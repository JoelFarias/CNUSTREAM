import streamlit as st
import geopandas as gpd
import pandas as pd
from typing import List, Optional, Tuple
import plotly.express as px
import plotly.graph_objects as go
import plotly.io as pio
import unicodedata
import os
import numpy as np
import duckdb
import logging
import psutil

st.set_page_config(
    page_title="Dashboard de Conflitos Ambientais",
    page_icon="üå≥",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.markdown("""
<style>
/* ---------- Fundo geral do app ---------- */
[data-testid="stAppViewContainer"] {
    background-color: #fefcf9;
    padding: 2rem;
    font-family: 'Segoe UI', sans-serif;
    color: #333333;
}

/* ---------- Sidebar ---------- */
[data-testid="stSidebar"] {
    background-color: #f3f0eb;
    border-right: 2px solid #d8d2ca;
}
[data-testid="stSidebar"] > div {
    padding: 1rem;
}

/* ---------- Bot√µes ---------- */
.stButton > button {
    background-color: #cbe4d2;
    color: #2d3a2f;
    border: 2px solid #a6c4b2;
    border-radius: 10px;
    padding: 0.5rem 1rem;
    font-weight: bold;
    transition: all 0.3s ease-in-out;
}
.stButton > button:hover {
    background-color: #b4d6c1;
    color: #1e2a21;
}

/* ---------- T√≠tulos e textos ---------- */
h1, h2, h3 {
    color: #4a4a4a;
}
h1 {
    font-size: 2.2rem;
    border-bottom: 2px solid #d8d2ca;
    padding-bottom: 0.5rem;
    margin-bottom: 1rem;
}

/* ---------- Tabs ---------- */
.stTabs [data-baseweb="tab"] {
    background-color: #ebe7e1;
    color: #333;
    border-radius: 0.5rem 0.5rem 0 0;
    padding: 0.5rem 1rem;
    margin-right: 0.25rem;
    font-weight: bold;
    border: none;
}
.stTabs [aria-selected="true"] {
    background-color: #d6ccc2;
    color: #111;
}

/* ---------- Text input ---------- */
.stTextInput > div > input {
    background-color: #f9f6f2;
    border: 1px solid #ccc;
    border-radius: 0.5rem;
    padding: 0.5rem;
}

/* ---------- Selectbox ---------- */
.stSelectbox > div {
    background-color: #f9f6f2;
    border-radius: 0.5rem;
}

/* ---------- Expander ---------- */
.stExpander > details {
    background-color: #f2eee9;
    border: 1px solid #ddd3c7;
    border-radius: 0.5rem;
    padding: 0.5rem;
}

/* ---------- Scrollbar ---------- */
::-webkit-scrollbar {
    width: 10px;
}
::-webkit-scrollbar-track {
    background: #f3f0eb;
}
::-webkit-scrollbar-thumb {
    background-color: #b4d6c1;
    border-radius: 10px;
    border: 2px solid #f3f0eb;
}
</style>
""", unsafe_allow_html=True)

def _apply_layout(fig: go.Figure, title: str, title_size: int = 16) -> go.Figure:
    fig.update_layout(
        template="pastel",
        title={
            "text": title,
            "x": 0.5,
            "xanchor": "center",
            "font_size": title_size
        },
        paper_bgcolor="white",   
        plot_bgcolor="white",     
        margin=dict(l=20, r=20, t=50, b=20),
        hovermode="x unified",
        legend=dict(
            bgcolor="rgba(255,255,255,0.8)",
            bordercolor="#CCC",
            borderwidth=1,
            font=dict(size=10)
        )
    )
    return fig

base_layout = go.Layout(
    font=dict(family="Times New Roman", size=12),
    plot_bgcolor='white',
    paper_bgcolor='white',
    colorway=px.colors.qualitative.Pastel,
    margin=dict(l=20, r=20, t=40, b=20),
    xaxis=dict(showgrid=False),
    yaxis=dict(showgrid=False),
    hoverlabel=dict(
        bgcolor="white",
        font_size=12,
        font_family="Times New Roman"
    )
)

pastel_template = go.layout.Template(layout=base_layout)
pio.templates["pastel"] = pastel_template
pio.templates.default = "pastel"
PASTEL_SEQ = px.colors.qualitative.Pastel + px.colors.qualitative.Pastel1 + px.colors.qualitative.Pastel2

_original_px_bar = px.bar

st.title("An√°lise de Conflitos em √Åreas Protegidas e Territ√≥rios Tradicionais")
st.markdown("Monitoramento integrado de sobreposi√ß√µes em Unidades de Conserva√ß√£o, Terras Ind√≠genas e Territ√≥rios Quilombolas")
st.markdown("---")

def _patched_px_bar(*args, **kwargs) -> go.Figure:
    fig: go.Figure = _original_px_bar(*args, **kwargs)
    seq = PASTEL_SEQ
    barmode = getattr(fig.layout, 'barmode', '') or ''
    barras = [t for t in fig.data if isinstance(t, go.Bar)]
    if barmode == 'stack':
        for i, trace in enumerate(barras):
            trace.marker.color = seq[i % len(seq)]
    else:
        if len(barras) == 1:
            trace = barras[0]
            vals = trace.x if getattr(trace, 'orientation', None) != 'h' else trace.y
            if hasattr(vals, 'tolist'):
                vals = vals.tolist()
            trace.marker.color = [seq[i % len(seq)] for i in range(len(vals))]
        else:
            for i, trace in enumerate(barras):
                trace.marker.color = seq[i % len(seq)]
    return fig

px.bar = _patched_px_bar

@st.cache_data(persist="disk")
def carregar_shapefile(caminho: str, calcular_percentuais: bool = True, columns: list[str] = None) -> gpd.GeoDataFrame:
    gdf = gpd.read_file(caminho, columns=columns or [])
    
    gdf["geometry"] = gdf["geometry"].apply(lambda geom: geom.buffer(0) if geom and not geom.is_valid else geom)
    gdf = gdf[gdf["geometry"].notnull() & gdf["geometry"].is_valid]
    
    gdf_original_crs = gdf.crs # Store original CRS

    if "area_km2" in gdf.columns or calcular_percentuais:
        try:
            # Project to a suitable CRS for area calculation and simplification (e.g., UTM)
            gdf_proj = gdf.to_crs("EPSG:31983") 
            
            # Simplify geometry in the projected CRS
            # Tolerance of 10 (meters for EPSG:31983) is a starting point.
            gdf_proj.geometry = gdf_proj.geometry.simplify(tolerance=10, preserve_topology=True) 
            
            gdf_proj["area_calc_km2"] = gdf_proj.geometry.area / 1e6 # Calculate area with simplified geom
            
            # Update the original gdf (still in original CRS) with simplified geometries projected back
            gdf.geometry = gdf_proj.to_crs(gdf_original_crs).geometry

            if "area_km2" in gdf.columns:
                # Use calculated area from simplified_proj_geom if area_km2 is missing/zero
                gdf["area_km2"] = gdf["area_km2"].replace(0, np.nan).fillna(gdf_proj["area_calc_km2"])
            else:
                gdf["area_km2"] = gdf_proj["area_calc_km2"]

        except Exception as e:
            st.warning(f"Could not reproject/simplify for area calculation: {e}. Using existing 'area_km2' or skipping area calcs.")
            if "area_km2" not in gdf.columns:
                 gdf["area_km2"] = np.nan

    if calcular_percentuais and "area_km2" in gdf.columns:
        gdf["perc_alerta"] = (gdf.get("alerta_km2", 0) / gdf["area_km2"]) * 100
        gdf["perc_sigef"] = (gdf.get("sigef_km2", 0) / gdf["area_km2"]) * 100
        gdf["perc_alerta"] = gdf["perc_alerta"].replace([np.inf, -np.inf], np.nan).fillna(0)
        gdf["perc_sigef"] = gdf["perc_sigef"].replace([np.inf, -np.inf], np.nan).fillna(0)
    else:
        if "perc_alerta" not in gdf.columns: gdf["perc_alerta"] = 0
        if "perc_sigef" not in gdf.columns: gdf["perc_sigef"] = 0

    gdf["id"] = gdf.index.astype(str)

    for col in gdf.columns:
        if gdf[col].dtype == 'float64':
            gdf[col] = pd.to_numeric(gdf[col], downcast='float', errors='coerce')
        elif gdf[col].dtype == 'int64':
            gdf[col] = pd.to_numeric(gdf[col], downcast='integer', errors='coerce')
        elif gdf[col].dtype == 'object':
            if len(gdf[col].unique()) / len(gdf) < 0.5: 
                 try:
                    gdf[col] = gdf[col].astype('category')
                 except Exception:
                    pass 
    
    result_gdf = gdf.to_crs("EPSG:4326")
    gc.collect()
    return result_gdf

def preparar_hectares(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    """Adiciona colunas em hectares ao GeoDataFrame."""
    gdf2 = gdf.copy()
    gdf2['alerta_ha'] = gdf2.get('alerta_km2', 0) * 100
    gdf2['sigef_ha']  = gdf2.get('sigef_km2', 0)  * 100
    gdf2['area_ha']   = gdf2.get('area_km2', 0)   * 100
    
    for col in ['alerta_ha', 'sigef_ha', 'area_ha']:
         if gdf2[col].dtype == 'float64':
            gdf2[col] = pd.to_numeric(gdf2[col], downcast='float', errors='coerce')
         elif gdf2[col].dtype == 'int64':
            gdf2[col] = pd.to_numeric(gdf2[col], downcast='integer', errors='coerce')

    return gdf2

@st.cache_data(persist="disk")
def load_csv(uploaded_file, columns: list[str] = None) -> pd.DataFrame:
    usecols_arg = None
    if columns is not None:
        usecols_arg = lambda col: col in columns

    try:
        df = pd.read_csv(
            uploaded_file,
            low_memory=False,
            usecols=usecols_arg
        )
    except UnicodeDecodeError:
        uploaded_file.seek(0)
        df = pd.read_csv(
            uploaded_file,
            low_memory=False,
            usecols=usecols_arg,
            encoding='latin-1'
        )
    except Exception as e:
        st.error(f"Erro ao ler o arquivo CSV: {e}")
        return pd.DataFrame()


    if "Unnamed: 0" in df.columns:
        df = df.rename(columns={"Unnamed: 0": "Munic√≠pio"})
    
    cols_ocorrencias = [
        "√Åreas de conflitos", "Assassinatos", "Conflitos por Terra",
        "Ocupa√ß√µes Retomadas", "Tentativas de Assassinatos", "Trabalho Escravo"
    ]
    existing = [c for c in cols_ocorrencias if c in df.columns]
    
    if existing:
        df["total_ocorrencias"] = df[existing].sum(axis=1)
        df["total_ocorrencias"] = pd.to_numeric(
            df["total_ocorrencias"],
            downcast='integer',
            errors='coerce'
        )
    else:
        df["total_ocorrencias"] = 0

    for col in df.columns:
        dtype = df[col].dtype
        if dtype == 'float64':
            df[col] = pd.to_numeric(df[col], downcast='float', errors='coerce')
        elif dtype == 'int64':
            df[col] = pd.to_numeric(df[col], downcast='integer', errors='coerce')
        elif dtype == 'object':
            if df[col].nunique() / len(df) < 0.5:
                try:
                    df[col] = df[col].astype('category')
                except Exception:
                    pass
    gc.collect()
    return df
    
@st.cache_data(persist="disk")
def carregar_dados_conflitos_municipio(arquivo_excel: str) -> pd.DataFrame:
    try:
        df = pd.read_excel(arquivo_excel, sheet_name='√Åreas em Conflito', usecols=['mun', 'Fam√≠lias', 'Nome do Conflito']).dropna(how='all')
    except Exception as e:
        st.error(f"Erro ao ler o arquivo Excel de conflitos: {e}")
        return pd.DataFrame()

    lista_original = ['S√ÉO F√âLIX DO XINGU', 'ALTAMIRA', 'ITAITUBA',
                      'JACAREACANGA', 'NOVO PROGRESSO']

    def clean_mun_name(name):
        if pd.isna(name):
            return None
        name = str(name).strip().lower()
        name = unicodedata.normalize('NFD', name).encode('ascii', 'ignore').decode('utf-8')
        return name

    lista_limpa = [clean_mun_name(m) for m in lista_original]
    lista_limpa = [m for m in lista_limpa if m is not None] 

    df['mun_limpo_list'] = df['mun'].apply(lambda x: [
        clean_mun_name(m) for m in str(x).replace(';', ',').split(',')
    ])
    df_exploded = df.explode('mun_limpo_list')
    df_exploded = df_exploded[df_exploded['mun_limpo_list'].notna() & (df_exploded['mun_limpo_list'] != '')].copy()
    df_filtered = df_exploded[df_exploded['mun_limpo_list'].isin(lista_limpa)].copy()

    if df_filtered.empty:
        st.warning("Nenhum munic√≠pio da lista de interesse encontrado nos dados de conflitos ap√≥s a limpeza.")
        return pd.DataFrame(columns=['Munic√≠pio', 'Total_Fam√≠lias', 'N√∫mero_Conflitos'])

    df_filtered['Fam√≠lias'] = pd.to_numeric(df_filtered['Fam√≠lias'], errors='coerce').fillna(0)
    df_filtered['Fam√≠lias'] = pd.to_numeric(df_filtered['Fam√≠lias'], downcast='integer', errors='coerce')
    conflitos_presentes = df_filtered['Nome do Conflito'].unique()
    df_conflitos_relevantes = df_exploded[df_exploded['Nome do Conflito'].isin(conflitos_presentes)].copy()

    df_conflitos_relevantes['num_mun'] = df_conflitos_relevantes.groupby('Nome do Conflito', observed=False)['mun_limpo_list'].transform('nunique')
    df_conflitos_relevantes['Fam_por_mun'] = df_conflitos_relevantes['Fam√≠lias'] / df_conflitos_relevantes['num_mun']

    df_conflitos_relevantes['num_mun'] = pd.to_numeric(df_conflitos_relevantes['num_mun'], downcast='integer', errors='coerce')
    df_conflitos_relevantes['Fam_por_mun'] = pd.to_numeric(df_conflitos_relevantes['Fam_por_mun'], downcast='float', errors='coerce')

    res = df_conflitos_relevantes.groupby('mun_limpo_list', observed=False).agg({
        'Fam_por_mun':'sum', 
        'Nome do Conflito':'count'
    }).reset_index()

    res.columns = ['Munic√≠pio_Limpo','Total_Fam√≠lias','N√∫mero_Conflitos']
    res = res.rename(columns={'Munic√≠pio_Limpo': 'Munic√≠pio'})
    cleaned_to_original_map = {clean_mun_name(orig): orig.title() for orig in lista_original}
    res['Munic√≠pio'] = res['Munic√≠pio'].map(cleaned_to_original_map).fillna(res['Munic√≠pio']) 

    res['Total_Fam√≠lias'] = pd.to_numeric(res['Total_Fam√≠lias'], downcast='integer', errors='coerce')
    res['N√∫mero_Conflitos'] = pd.to_numeric(res['N√∫mero_Conflitos'], downcast='integer', errors='coerce')

    if not res.empty and len(res['Munic√≠pio'].unique()) / len(res) < 0.5:
        try:
            res['Munic√≠pio'] = res['Munic√≠pio'].astype('category')
        except Exception:
            pass
    gc.collect()
    return res

def criar_figura(gdf_cnuc_filtered, gdf_sigef_filtered, df_csv_filtered, centro, ids_selecionados, invadindo_opcao):
    try:
        fig = px.choropleth_map(
            gdf_cnuc_filtered,
            geojson=gdf_cnuc_filtered.__geo_interface__,
            locations=gdf_cnuc_filtered.index,
            color=np.ones(len(gdf_cnuc_filtered)),
            color_continuous_scale=[[0, "rgb(200,200,200)"], [1, "rgb(200,200,200)"]],
            map_style="open-street-map",
            zoom=5,
            center=centro,
            opacity=0.5,
            hover_data={
                'nome_uc': True,
                'municipio': True,
                'area_km2': ':.2f',
                'alerta_km2': ':.2f',
                'sigef_km2': ':.2f'
            }
        )
        fig.update_traces(
            hovertemplate=(
                "<b>%{customdata[0]}</b><br>" +
                "Munic√≠pio: %{customdata[1]}<br>" +
                "√Årea: %{customdata[2]:.2f} km¬≤<br>" +
                "Alertas: %{customdata[3]:.2f} km¬≤<br>" +
                "CAR: %{customdata[4]:.2f} km¬≤<extra></extra>"
            )
        )

        if invadindo_opcao:
            if invadindo_opcao.lower() == "todos":
                sigef_plot = gdf_sigef_filtered
            else:
                sigef_plot = gdf_sigef_filtered[
                    gdf_sigef_filtered["invadindo"].str.strip().str.lower() == invadindo_opcao.lower()
                ]
            
            if not sigef_plot.empty:
                fig_sigef = px.choropleth_map(
                    sigef_plot,
                    geojson=sigef_plot.__geo_interface__,
                    locations=sigef_plot.index,
                    color=np.ones(len(sigef_plot)),
                    color_continuous_scale=[[0, "rgba(255,65,54,0.5)"], [1, "rgba(255,65,54,0.5)"]],
                    opacity=0.5
                )
                for trace in fig_sigef.data:
                    fig.add_trace(trace)

        if df_csv_filtered is not None and not df_csv_filtered.empty:
            df_plot = df_csv_filtered.dropna(subset=['Latitude', 'Longitude']).drop_duplicates(subset=['Munic√≠pio'])
            
            if not df_plot.empty:
                conflitos_cols = [
                    '√Åreas de conflitos', 'Assassinatos', 'Conflitos por Terra',
                    'Ocupa√ß√µes Retomadas', 'Tentativas de Assassinatos', 'Trabalho Escravo'
                ]
                
                existing_cols = [col for col in conflitos_cols if col in df_plot.columns]
                
                if existing_cols:
                    customdata = df_plot[existing_cols]
                    hovertemplate = "<b>%{text}</b><br>"
                    for i, col in enumerate(existing_cols):
                        hovertemplate += f"{col}: %{{customdata[{i}]}}<br>"
                    hovertemplate += "<extra></extra>"
                else:
                    customdata = [[]] * len(df_plot)
                    hovertemplate = "<b>%{text}</b><extra></extra>"

                fig.add_trace(
                    go.Scattermapbox(
                        lat=df_plot['Latitude'],
                        lon=df_plot['Longitude'],
                        mode='markers+text',
                        marker=dict(
                            size=12,
                            color='red',
                            opacity=0.7,
                            symbol='circle'
                        ),
                        text=df_plot['Munic√≠pio'],
                        textposition="top center",
                        textfont=dict(size=10, color="black"),
                        hovertemplate=hovertemplate,
                        customdata=customdata,
                        name='Munic√≠pios'
                    )
                )

        fig.update_layout(
            mapbox=dict(
                style="open-street-map",
                zoom=5,
                center=centro
            ),
            showlegend=True,
            margin=dict(l=0, r=0, t=0, b=0),
            height=600,
            legend=dict(
                yanchor="top",
                y=0.99,
                xanchor="left",
                x=0.01,
                bgcolor="rgba(255,255,255,0.8)"
            ),
        )
        
        return fig

    except Exception as e:
        st.error(f"Erro ao criar mapa: {e}")
        return go.Figure()
    
def criar_cards(gdf_cnuc_filtered, gdf_sigef_filtered, invadindo_opcao):
    try:
        ucs_selecionadas = gdf_cnuc_filtered.copy()
        sigef_base = gdf_sigef_filtered.copy()
        
        if ucs_selecionadas.empty:
            return (0.0, 0.0, 0, 0, 0)

        crs_proj = "EPSG:31983"
        ucs_proj = ucs_selecionadas.to_crs(crs_proj)
        sigef_proj = sigef_base.to_crs(crs_proj)

        if invadindo_opcao and invadindo_opcao.lower() != "todos":
            mascara = sigef_proj["invadindo"].str.strip().str.lower() == invadindo_opcao.strip().lower()
            sigef_filtrado = sigef_proj[mascara].copy()
        else:
            sigef_filtrado = sigef_proj.copy()
        if not ucs_proj.empty and not sigef_filtrado.empty:
            sobreposicao = gpd.overlay(
                ucs_proj,
                sigef_filtrado,
                how='intersection',
                keep_geom_type=False,
                make_valid=True
            )
            sobreposicao['area_sobreposta'] = sobreposicao.geometry.area / 1e6
            total_sigef = sobreposicao['area_sobreposta'].sum()
            contagem_sigef_overlay = sobreposicao.shape[0]
        else:
            total_sigef = 0.0
            contagem_sigef_overlay = 0

        total_area_ucs = ucs_proj.geometry.area.sum() / 1e6
        total_alerta = ucs_selecionadas.get("alerta_km2", pd.Series([0])).sum()
        contagem_alerta_uc = ucs_selecionadas.get("c_alertas", pd.Series([0])).sum() 

        perc_alerta = (total_alerta / total_area_ucs * 100) if total_area_ucs > 0 else 0
        perc_sigef = (total_sigef / total_area_ucs * 100) if total_area_ucs > 0 else 0

        municipios = set()
        if "municipio" in ucs_selecionadas.columns:
            for munic in ucs_selecionadas["municipio"]:
                if pd.notna(munic):
                    partes = str(munic).replace(';', ',').split(',')
                    for parte in partes:
                        if parte.strip():
                            municipios.add(parte.strip().title())

        return (
            round(perc_alerta, 1),
            round(perc_sigef, 1),
            len(municipios),
            int(contagem_alerta_uc),
            int(contagem_sigef_overlay) 
        ) 

    except Exception as e:
        st.error(f"Erro cr√≠tico ao criar cards: {str(e)}")
        return (0.0, 0.0, 0, 0, 0)
    
def render_cards(perc_alerta, perc_sigef, total_unidades, contagem_alerta, contagem_sigef):
    col1, col2, col3, col4, col5 = st.columns(5, gap="small")
    
    card_html_template = """
    <div style="
        background: rgba(255,255,255,0.9);
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
        height: 100px;  <!-- Fixed height -->
        display: flex;
        flex-direction: column;
        justify-content: center;">
        <div style="font-size: 0.9rem; color: #6FA8DC;">{titulo}</div>
        <div style="font-size: 1.2rem; font-weight: bold; color: #2F5496;">{valor}</div>
        <div style="font-size: 0.7rem; color: #666;">{descricao}</div>
    </div>
    """
    
    with col1:
        st.markdown(
            card_html_template.format(
                titulo="Alertas / Ext. Ter.",
                valor=f"{perc_alerta:.1f}%",
                descricao="√Årea de alertas sobre extens√£o territorial"
            ),
            unsafe_allow_html=True
        )
    
    with col2:
        st.markdown(
            card_html_template.format(
                titulo="CARs / Ext. Ter.", 
                valor=f"{perc_sigef:.1f}%",
                descricao="CARs sobre extens√£o territorial"
            ),
            unsafe_allow_html=True
        )
    
    with col3:
        st.markdown(
            card_html_template.format(
                titulo="Munic√≠pios Abrangidos",
                valor=f"{total_unidades}",
                descricao="Total de munic√≠pios na an√°lise"
            ),
            unsafe_allow_html=True
        )

    with col4:
        st.markdown(
            card_html_template.format(
                titulo="Alertas",
                valor=f"{contagem_alerta}",
                descricao="Total de registros de alertas"
            ),
            unsafe_allow_html=True
        )

    with col5:
        st.markdown(
            card_html_template.format(
                titulo="CARs",
                valor=f"{contagem_sigef}",
                descricao="Cadastros Ambientais Rurais"
            ),
            unsafe_allow_html=True
        )

import textwrap

def truncate(text, max_chars=15):
    return text if len(text) <= max_chars else text[:max_chars-3] + "..."

def wrap_label(name, width=30):
    if pd.isna(name): return ""
    return "<br>".join(textwrap.wrap(str(name), width))

def fig_sobreposicoes(gdf_cnuc_ha_filtered):
    gdf = gdf_cnuc_ha_filtered.copy().sort_values("area_ha", ascending=False)
    if gdf.empty:
        return go.Figure()

    gdf["uc_short"] = gdf["nome_uc"].apply(lambda x: wrap_label(x, 15))
    
    fig = px.bar(
        gdf,
        x="uc_short",
        y=["alerta_ha","sigef_ha","area_ha"],
        labels={"value":"√Årea (ha)","uc_short":"UC"},
        barmode="stack",
        text_auto=True,
    )
    fig.update_traces(
        customdata=np.stack([gdf.alerta_ha, gdf.sigef_ha, gdf.area_ha, gdf.nome_uc], axis=-1),
        hovertemplate=(
            "<b>%{customdata[3]}</b><br>"
            "Alerta: %{customdata[0]:.0f} ha<br>"
            "CAR:     %{customdata[1]:.0f} ha<br>"
            "Total:   %{customdata[2]:.0f} ha<extra></extra>"
        ),
        texttemplate="%{y:.0f}",
        textposition="inside",
        marker_line_color="rgb(80,80,80)",
        marker_line_width=0.5,
    )
    media = gdf["area_ha"].mean()
    fig.add_shape(
        type="line", x0=-0.5, x1=len(gdf["uc_short"])-0.5,
        y0=media, y1=media,
        line=dict(color="FireBrick", width=2, dash="dash"),
    )
    fig.add_annotation(
        x=len(gdf["uc_short"])-0.5, y=media,
        text=f"M√©dia = {media:.0f} ha",
        showarrow=False, yshift=10,
        font=dict(color="FireBrick", size=10)
    )
    fig.update_xaxes(tickangle=0, tickfont=dict(size=9), title_text="")
    fig.update_yaxes(title_text="√Årea (ha)", tickfont=dict(size=9))
    fig.update_layout(height=400)
    return _apply_layout(fig, title="√Åreas por UC", title_size=16)

def fig_contagens_uc(gdf_cnuc_filtered: gpd.GeoDataFrame) -> go.Figure:
    gdf = gdf_cnuc_filtered.copy()
    if gdf.empty:
        return go.Figure()
    gdf["total_counts"] = gdf.get("c_alertas", 0) + gdf.get("c_sigef", 0)
    gdf = gdf.sort_values("total_counts", ascending=False)
    
    gdf["uc_wrap"] = gdf["nome_uc"].apply(lambda x: wrap_label(x, 15))
    
    fig = px.bar(
        gdf,
        x="uc_wrap",
        y=["c_alertas","c_sigef"],
        labels={"value":"Contagens","uc_wrap":"UC"},
        barmode="stack",
        text_auto=True,
    )
    
    fig.update_traces(
        customdata=np.stack([gdf.get("c_alertas", 0), gdf.get("c_sigef", 0), gdf.total_counts, gdf.nome_uc], axis=-1),
        hovertemplate=(
            "<b>%{customdata[3]}</b><br>"
            "Alertas: %{customdata[0]}<br>"
            "CARs:    %{customdata[1]}<br>"
            "Total:   %{customdata[2]}<extra></extra>"
        ),
        texttemplate="%{y:.0f}",
        textposition="inside",
        marker_line_color="rgb(80,80,80)",
        marker_line_width=0.5,
    )
    
    media = gdf["total_counts"].mean()
    fig.add_shape(
        type="line",
        x0=-0.5, x1=len(gdf["uc_wrap"])-0.5,
        y0=media, y1=media,
        line=dict(color="FireBrick", width=2, dash="dash"),
    )
    fig.add_annotation(
        x=len(gdf["uc_wrap"])-0.5, y=media,
        text=f"M√©dia = {media:.0f}",
        showarrow=False, yshift=10,
        font=dict(color="FireBrick", size=10)
    )
    
    fig.update_xaxes(tickangle=0, tickfont=dict(size=9), title_text="")
    fig.update_yaxes(title_text="Contagens", tickfont=dict(size=9))
    fig.update_layout(height=400)
    
    return _apply_layout(fig, title="Contagens por UC", title_size=16)

def fig_car_por_uc_donut(gdf_cnuc_ha_filtered: gpd.GeoDataFrame, nome_uc: str, modo_valor: str = "percent") -> go.Figure:
    gdf_cnuc_ha = gdf_cnuc_ha_filtered.copy()
    if gdf_cnuc_ha.empty:
         return go.Figure()

    if nome_uc == "Todas":
        area_total = gdf_cnuc_ha["area_ha"].sum()
        area_car = gdf_cnuc_ha["sigef_ha"].sum()
    else:
        row = gdf_cnuc_ha[gdf_cnuc_ha["nome_uc"] == nome_uc]
        if row.empty:
            return go.Figure() 
            
        area_total = row["area_ha"].values[0]
        area_car = row["sigef_ha"].values[0]

    total_chart = max(area_total, area_car)
    restante_chart = total_chart - area_car
    percentual = (area_car / area_total) * 100 if area_total and area_total > 0 else 0
    
    if modo_valor == "percent":
        textinfo = "label+percent"
        center_text = f"{percentual:.1f}%"
    else:
        textinfo = "label+value"
        center_text = f"{area_car:,.0f} ha"
        
    fig = go.Figure(data=[go.Pie(
        labels=["√Årea CAR", "√Årea restante"],
        values=[area_car, restante_chart],
        hole=0.6,
        marker_colors=["#2ca02c", "#d9d9d9"],
        textinfo=textinfo,
        hoverinfo="label+value+percent"
    )])
    fig.update_layout(
        title_text=f"Ocupa√ß√£o do CAR em: {nome_uc}",
        annotations=[dict(text=center_text, x=0.5, y=0.5, font_size=22, showarrow=False)],
        height=400
    )
    return _apply_layout(fig, title=f"Ocupa√ß√£o do CAR em: {nome_uc}", title_size=16)

def fig_familias(df_conflitos_filtered: pd.DataFrame) -> go.Figure:
    df = df_conflitos_filtered.sort_values('Total_Fam√≠lias', ascending=False)
    if df.empty:
        return go.Figure()

    max_val = df['Total_Fam√≠lias'].max()

    fig = px.bar(
        df,
        x='Total_Fam√≠lias',
        y='Munic√≠pio',
        orientation='h',
        text='Total_Fam√≠lias',
        labels={'Total_Fam√≠lias': 'Total de Fam√≠lias', 'Munic√≠pio': ''}
    )
    fig = _apply_layout(fig, title="Fam√≠lias Afetadas")

    fig.update_layout(
        yaxis=dict(autorange="reversed"),
        xaxis=dict(
            range=[0, max_val * 1.1],      
            tickformat=',d'                 
        ),
        margin=dict(l=80, r=100, t=50, b=20) 
    )

    fig.update_traces(
        texttemplate='%{text:.0f}',
        textposition='outside',
        cliponaxis=False,                 
        marker_line_color='rgb(80,80,80)',
        marker_line_width=0.5
    )

    return fig

def fig_conflitos(df_conflitos_filtered: pd.DataFrame) -> go.Figure:
    df = df_conflitos_filtered.sort_values('N√∫mero_Conflitos', ascending=False)
    if df.empty:
        return go.Figure() 

    fig = px.bar(
        df, x='N√∫mero_Conflitos', y='Munic√≠pio', orientation='h',
        text='N√∫mero_Conflitos'
    )
    fig = _apply_layout(fig, title="Conflitos Registrados")
    fig.update_layout(
        yaxis=dict(autorange="reversed")
    )
    fig.update_traces(
        texttemplate='%{text:.0f}',
        textposition='outside',
        marker_line_color='rgb(80,80,80)',
        marker_line_width=0.5
    )
    return fig
    
def clean_text(text: str) -> str:
    if pd.isna(text): return text
    text = str(text).strip().lower()
    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')

def fig_justica(df_proc_filtered: pd.DataFrame) -> dict[str, go.Figure]:
    df_proc = df_proc_filtered.copy()
    figs = {}
    palette = px.defaults.color_discrete_sequence
    bottom_margin = 100

    mapa_classes = {
        "procedimento comum civel": "Proc. Comum C√≠vel",
        "acao civil publica": "A√ß√£o Civil P√∫blica",
        "peticao civel": "Peti√ß√£o C√≠vel",
        "cumprimento de sentenca": "Cumpr. Senten√ßa",
        "termo circunstanciado": "Termo Circunstan.",
        "carta precatoria civel": "Carta Prec. C√≠vel",
        "acao penal - procedimento ordinario": "A√ß√£o Penal Ordin√°ria",
        "alvara judicial - lei 6858/80": "Alvar√° Judicial",
        "crimes ambientais": "Crimes Ambientais",
        "homologacao da transacao extrajudicial": "Homolog. Transa√ß√£o"
    }

    mapa_assuntos = {
        "indenizacao por dano ambiental": "Dano Ambiental",
        "obrigacao de fazer / nao fazer": "Obrig. Fazer/N√£o Fazer",
        "flora": "Flora",
        "fauna": "Fauna",
        "mineracao": "Minera√ß√£o",
        "poluicao": "Polui√ß√£o",
        "unidade de conservacao da natureza": "Unid. Conserva√ß√£o",
        "revogacao/anulacao de multa ambiental": "Anula√ß√£o Multa Ambiental",
        "area de preservacao permanente": "APP",
        "agrotoxicos": "Agrot√≥xicos"
    }

    mapa_orgaos = {
        "1a vara civel e empresarial de altamira": "1¬™ V. C√≠vel Altamira",
        "vara civil e empresarial da comarca de sao felix do xingu": "V. C√≠vel S√£o F√©lix",
        "vara civel de novo progresso": "V. C√≠vel Novo Progresso",
        "2a vara civel e empresarial de altamira": "2¬™ V. C√≠vel Altamira",
        "3a vara civel e empresarial de altamira": "3¬™ V. C√≠vel Altamira",
        "1a vara civel e empresarial de itaituba": "1¬™ V. C√≠vel Itaituba",
        "juizado especial civel e criminal de itaituba": "JEC Itaituba",
        "2a vara civel e empresarial de itaituba": "2¬™ V. C√≠vel Itaituba",
        "vara criminal de itaituba": "V. Criminal Itaituba",
        "vara unica de jacareacanga": "V. √önica Jacareacanga"
    }

    # Top 10 Munic√≠pios
    if 'municipio' in df_proc.columns and not df_proc.empty:
        df_proc['municipio'] = df_proc['municipio'].apply(clean_text)
        top = df_proc['municipio'].value_counts().head(10).reset_index()
        top.columns = ['Municipio', 'Quantidade']
        if not top.empty:
            top['label'] = top['Municipio'].apply(lambda x: wrap_label(x, 20))
            fig_mun = px.bar(
                top, y='label', x='Quantidade', orientation='h',
                color_discrete_sequence=palette
            )
            fig_mun.update_traces(texttemplate='%{x}', textposition='auto', cliponaxis=False)
            fig_mun.update_layout(
                margin=dict(l=150, r=60, t=50, b=bottom_margin),
                height=500,
                yaxis=dict(autorange="reversed")
            )
            figs['mun'] = _apply_layout(fig_mun, "Top 10 Munic√≠pios com Mais Processos", 16)
        else:
             figs['mun'] = go.Figure().update_layout(title="Top 10 Munic√≠pios com Mais Processos", annotations=[dict(text="Sem dados", showarrow=False)])
    else:
         figs['mun'] = go.Figure().update_layout(title="Top 10 Munic√≠pios com Mais Processos", annotations=[dict(text="Sem dados", showarrow=False)])


    # Evolu√ß√£o Mensal de Processos
    if 'data_ajuizamento' in df_proc.columns and not df_proc.empty:
        df_proc['ano_mes'] = (
            pd.to_datetime(df_proc['data_ajuizamento'], errors='coerce')
              .dt.to_period('M')
              .dt.to_timestamp()
        )
        mensal = df_proc.groupby('ano_mes', observed=False).size().reset_index(name='Quantidade')
        if not mensal.empty:
            fig_temp = px.line(
                mensal,
                x='ano_mes', y='Quantidade',
                markers=True, text='Quantidade'
            )
            fig_temp.update_traces(
                mode='lines+markers+text',
                textposition='top center',
                texttemplate='%{text}'
            )
            fig_temp.update_layout(
                margin=dict(l=80, r=60, t=50, b=bottom_margin),
                height=400,
                yaxis=dict(range=[0, mensal['Quantidade'].max() * 1.1])
            )
            figs['temp'] = _apply_layout(fig_temp, "Evolu√ß√£o Mensal de Processos", 16)
        else:
             figs['temp'] = go.Figure().update_layout(title="Evolu√ß√£o Mensal de Processos", annotations=[dict(text="Sem dados", showarrow=False)])
    else:
         figs['temp'] = go.Figure().update_layout(title="Evolu√ß√£o Mensal de Processos", annotations=[dict(text="Sem dados", showarrow=False)])


    # Top 10 Classes, Assuntos e √ìrg√£os
    mappings = [
        ('class', 'classe', 'Top 10 Classes Processuais', mapa_classes),
        ('ass', 'assuntos', 'Top 10 Assuntos', mapa_assuntos),
        ('org', 'orgao_julgador', 'Top 10 √ìrg√£os Julgadores', mapa_orgaos)
    ]

    for key, col, title, mapa in mappings:
        if col in df_proc.columns and not df_proc.empty:
            series_de_strings_limpas = df_proc[col].apply(clean_text)
            series_categorica = pd.Series(series_de_strings_limpas, dtype="category")
            try:
                series_com_categorias_renomeadas = series_categorica.cat.rename_categories(mapa)
            except ValueError as e:
                print(f"Aviso para coluna '{col}': N√£o foi poss√≠vel renomear todas as categorias usando o mapa fornecido. Verifique se as chaves do mapa correspondem √†s categorias existentes ap√≥s clean_text. Erro: {e}")
                series_com_categorias_renomeadas = series_de_strings_limpas.replace(mapa)
                series_com_categorias_renomeadas = pd.Series(series_com_categorias_renomeadas, dtype="category")

            df = (
                series_com_categorias_renomeadas
                .value_counts()
                .head(10)
                .reset_index()
            )
            
            df.columns = [col, 'Quantidade']
            
            if not df.empty:
                df['label'] = df[col].apply(lambda x: wrap_label(x, 30))
                fig = px.bar(
                    df, y='label', x='Quantidade', orientation='h',
                    color_discrete_sequence=palette
                )
                fig.update_traces(texttemplate='%{x}', textposition='auto', cliponaxis=False)
                fig.update_layout(
                    margin=dict(l=180, r=60, t=50, b=bottom_margin),
                    height=500,
                    yaxis=dict(autorange="reversed")
                )
                figs[key] = _apply_layout(fig, title, 16)
            else:
                figs[key] = go.Figure().update_layout(title=title, annotations=[dict(text="Sem dados", showarrow=False)])
        else:
            figs[key] = go.Figure().update_layout(title=title, annotations=[dict(text="Sem dados", showarrow=False)])

    return figs 

def graficos_inpe(data_frame_entrada: pd.DataFrame, ano_selecionado_str: str) -> dict[str, go.Figure]:
    df = data_frame_entrada.copy()
    def create_placeholder_fig(title_message: str) -> go.Figure:
        fig = go.Figure()
        fig.update_layout(
            title=title_message,
            xaxis_visible=False,
            yaxis_visible=False,
            annotations=[dict(text="N√£o h√° dados suficientes para exibir este gr√°fico.", showarrow=False, xref="paper", yref="paper", x=0.5, y=0.5)]
        )
        return fig

    base_error_title = f"Per√≠odo: {ano_selecionado_str}"

    if df.empty:
        return {
            'temporal': create_placeholder_fig(f"Evolu√ß√£o Temporal ({base_error_title})"),
            'top_risco': create_placeholder_fig(f"Top Risco ({base_error_title})"),
            'top_precip': create_placeholder_fig(f"Top Precipita√ß√£o ({base_error_title})"),
            'mapa': create_placeholder_fig(f"Mapa de Focos ({base_error_title})")
        }

    # --- Gr√°fico de Evolu√ß√£o Temporal do Risco de Fogo ---
    fig_temp = create_placeholder_fig(f"Evolu√ß√£o Temporal do Risco de Fogo ({ano_selecionado_str})")
    if 'DataHora' in df.columns and 'RiscoFogo' in df.columns:
        df_temp_indexed = df.set_index('DataHora')
        df_risco_valido_temp = df_temp_indexed[df_temp_indexed['RiscoFogo'].between(0, 1)]
        if not df_risco_valido_temp.empty:
            monthly_risco = df_risco_valido_temp['RiscoFogo'].resample('ME').mean().reset_index()
            monthly_risco['RiscoFogo'] = monthly_risco['RiscoFogo'].fillna(0)

            if not monthly_risco.empty:
                fig_temp = go.Figure()
                fig_temp.add_trace(go.Scatter(
                    x=monthly_risco['DataHora'].dt.to_period('M').astype(str),
                    y=monthly_risco['RiscoFogo'],
                    name='Risco de Fogo Mensal',
                    mode='lines+markers+text',
                    marker=dict(size=8, color='#FF4136', line=dict(width=1, color='#444')),
                    line=dict(width=2, color='#FF4136'),
                    text=[f'{v:.2f}' for v in monthly_risco['RiscoFogo']],
                    textposition='top center'
                ))
                fig_temp.update_layout(
                    title_text=f'Evolu√ß√£o Mensal do Risco de Fogo ({ano_selecionado_str})',
                    xaxis_title='M√™s',
                    yaxis_title='Risco M√©dio de Fogo',
                    height=400,
                    margin=dict(l=60, r=80, t=80, b=40),
                    showlegend=True,
                    hovermode='x unified'
                )

    # --- Gr√°fico Top Munic√≠pios por Risco de Fogo ---
    fig_risco = create_placeholder_fig(f"Top Munic√≠pios - Risco de Fogo ({ano_selecionado_str})")
    if 'mun_corrigido' in df.columns and 'RiscoFogo' in df.columns:
        df_risco_valido = df[df['RiscoFogo'].between(0, 1)]
        if not df_risco_valido.empty:
            top_risco_data = df_risco_valido.groupby('mun_corrigido', observed=False)['RiscoFogo'].mean().nlargest(10).sort_values()
            if not top_risco_data.empty:
                fig_risco = go.Figure(go.Bar(
                    y=top_risco_data.index,
                    x=top_risco_data.values,
                    orientation='h',
                    marker_color='#FF8C7A',
                    text=top_risco_data.values,
                    texttemplate='<b>%{text:.2f}</b>',
                    textposition='outside'
                ))
                fig_risco.update_layout(
                    title_text=f'Top Munic√≠pios por Risco M√©dio de Fogo ({ano_selecionado_str})',
                    xaxis_title='Risco M√©dio de Fogo',
                    yaxis_title='Munic√≠pio',
                    height=400,
                    margin=dict(l=100, r=80, t=50, b=40)
                )

    # --- Gr√°fico Top Munic√≠pios por Precipita√ß√£o ---
    fig_precip = create_placeholder_fig(f"Top Munic√≠pios - Precipita√ß√£o M√©dia ({ano_selecionado_str})")
    if 'mun_corrigido' in df.columns and 'Precipitacao' in df.columns:
        df_precip_valida = df[df['Precipitacao'] >= 0]
        if not df_precip_valida.empty:
            top_precip_data = df_precip_valida.groupby('mun_corrigido', observed=False)['Precipitacao'].mean().nlargest(10).sort_values()
            if not top_precip_data.empty:
                fig_precip = go.Figure(go.Bar(
                    y=top_precip_data.index,
                    x=top_precip_data.values,
                    orientation='h',
                    marker_color='#B3D9FF',
                    text=top_precip_data.values,
                    texttemplate='<b>%{text:.1f} mm</b>',
                    textposition='outside'
                ))
                fig_precip.update_layout(
                    title_text=f'Top Munic√≠pios por Precipita√ß√£o M√©dia ({ano_selecionado_str})',
                    xaxis_title='Precipita√ß√£o M√©dia (mm)',
                    yaxis_title='Munic√≠pio',
                    height=400,
                    margin=dict(l=100, r=80, t=50, b=40)
                )

    # --- Mapa de Distribui√ß√£o dos Focos de Calor ---
    fig_map = create_placeholder_fig(f"Mapa de Distribui√ß√£o dos Focos de Calor ({ano_selecionado_str})")
    map_required_cols = ['Latitude', 'Longitude', 'RiscoFogo', 'mun_corrigido', 'DataHora']
    if all(col in df.columns for col in map_required_cols):
        df_map_plot = df[map_required_cols + (['Precipitacao'] if 'Precipitacao' in df.columns else [])].copy()
        df_map_plot.dropna(subset=['Latitude', 'Longitude', 'RiscoFogo', 'mun_corrigido'], inplace=True)
        df_map_plot = df_map_plot[df_map_plot['RiscoFogo'].between(0, 1)]
        if 'Precipitacao' in df_map_plot.columns:
             df_map_plot = df_map_plot[df_map_plot['Precipitacao'] >= 0]
        else:
            df_map_plot['Precipitacao'] = 0

        if not df_map_plot.empty:
            sample_size = 50000
            if len(df_map_plot) > sample_size:
                df_map_plot_sampled = df_map_plot.sample(sample_size, random_state=1)
            else:
                df_map_plot_sampled = df_map_plot

            if not df_map_plot_sampled.empty:
                centro_map = {
                    'lat': df_map_plot_sampled['Latitude'].mean(),
                    'lon': df_map_plot_sampled['Longitude'].mean()
                }
                lat_range = df_map_plot_sampled['Latitude'].max() - df_map_plot_sampled['Latitude'].min()
                lon_range = df_map_plot_sampled['Longitude'].max() - df_map_plot_sampled['Longitude'].min()
                max_range = max(lat_range, lon_range, 0.01)

                zoom_level = 3.5
                if max_range < 1: zoom_level = 7
                elif max_range < 5: zoom_level = 5
                elif max_range < 10: zoom_level = 4

                hover_data_config = {
                    'Latitude': False, 'Longitude': False, 'DataHora': '|%d %b %Y',
                    'RiscoFogo': ':.2f', 'Precipitacao': ':.1f mm'
                }

                fig_map = px.scatter_map(
                    df_map_plot_sampled,
                    lat='Latitude',
                    lon='Longitude',
                    color='RiscoFogo',
                    size='Precipitacao' if 'Precipitacao' in df_map_plot_sampled.columns else None,
                    hover_name='mun_corrigido',
                    hover_data=hover_data_config,
                    color_continuous_scale=px.colors.sequential.YlOrRd,
                    size_max=15,
                    map_style="open-street-map",
                    zoom=zoom_level,
                    center=centro_map,
                    height=550
                ) 
                fig_map.update_layout(
                    title_text=f'Mapa de Distribui√ß√£o dos Focos de Calor ({ano_selecionado_str})',
                    coloraxis_showscale=False
                )

    return {
        'temporal': fig_temp,
        'top_risco': fig_risco,
        'top_precip': fig_precip,
        'mapa': fig_map
    }

def mostrar_tabela_unificada(gdf_alertas_filtered, gdf_sigef_filtered, gdf_cnuc_filtered):
    df_a = gdf_alertas_filtered[['MUNICIPIO', 'AREAHA']].rename(columns={'MUNICIPIO':'municipio', 'AREAHA':'alerta_ha'})

    if 'area_km2' not in gdf_sigef_filtered.columns:
        gdf_sigef_filtered = gdf_sigef_filtered.copy()
        gdf_sigef_filtered['area_km2'] = 0.0

    df_s = gdf_sigef_filtered[['municipio', 'area_km2']].rename(columns={'area_km2':'sigef_ha'})
    df_c = gdf_cnuc_filtered[['municipio', 'ha_total']].rename(columns={'ha_total':'uc_ha'}) 

    df_a['alerta_ha'] = pd.to_numeric(df_a['alerta_ha'], errors='coerce').fillna(0)
    df_s['sigef_ha'] = pd.to_numeric(df_s['sigef_ha'], errors='coerce').fillna(0) * 100
    df_c['uc_ha'] = pd.to_numeric(df_c['uc_ha'], errors='coerce').fillna(0)

    df_alertas_mun = df_a.groupby('municipio', observed=True, as_index=False)['alerta_ha'].sum()
    df_sigef_mun = df_s.groupby('municipio', observed=True, as_index=False)['sigef_ha'].sum()
    df_cnuc_mun = df_c.groupby('municipio', observed=True, as_index=False)['uc_ha'].sum()

    df_merged = df_alertas_mun.merge(df_sigef_mun, on='municipio', how='outer')
    df_merged = df_merged.merge(df_cnuc_mun, on='municipio', how='outer').fillna(0)

    cols = ['alerta_ha', 'sigef_ha', 'uc_ha']
    for c in cols:
        df_merged[c] = pd.to_numeric(df_merged[c], errors='coerce').fillna(0)
    
    total_alertas = df_merged['alerta_ha'].sum()
    total_sigef = df_merged['sigef_ha'].sum() 
    total_uc = df_merged['uc_ha'].sum()

    df_merged = df_merged[~((df_merged[cols] == 0).all(axis=1))]
    df_merged = df_merged.sort_values('municipio').reset_index(drop=True)
    df_merged = df_merged.rename(columns={
        'municipio': 'MUNIC√çPIO',
        'alerta_ha': 'ALERTAS(HA)',
        'sigef_ha': 'SIGEF(HA)', 
        'uc_ha': 'CNUC(HA)'
    })

    total_row = pd.DataFrame([{
        'MUNIC√çPIO': 'TOTAL(HA)',
        'ALERTAS(HA)': total_alertas,
        'SIGEF(HA)': total_sigef,
        'CNUC(HA)': total_uc
    }])
    
    df_merged = pd.concat([df_merged, total_row], ignore_index=True)

    styles = []
    colors = {
        'ALERTAS(HA)':'#fde0dd', 
        'SIGEF(HA)':'#e0ecf4', 
        'CNUC(HA)':'#edf8e9'
    }
    for i, c in enumerate(df_merged.columns):
        if c in colors:
            styles.append({'selector': f'td.col{i}', 'props': [('background-color', colors[c])]})
    
    styles.append({
        'selector': 'tr:last-child',
        'props': [('font-weight', 'bold'), ('background-color', '#f0f0f0')]
    })

    styled = (
        df_merged.style
                 .format({c:'{:,.2f}' for c in ['ALERTAS(HA)', 'SIGEF(HA)', 'CNUC(HA)']})
                 .set_table_styles(styles)
                 .set_table_attributes('style="border-collapse:collapse"')
    )

    st.subheader("Tabela √Årea")
    st.markdown(styled.to_html(), unsafe_allow_html=True)

def fig_desmatamento_uc(gdf_cnuc_filtered: gpd.GeoDataFrame, gdf_alertas_filtered: gpd.GeoDataFrame) -> go.Figure:
    if gdf_cnuc_filtered.empty or gdf_alertas_filtered.empty:
        return go.Figure() 

    crs_proj = "EPSG:31983" 
    gdf_cnuc_proj = gdf_cnuc_filtered.to_crs(crs_proj)
    gdf_alertas_proj = gdf_alertas_filtered.to_crs(crs_proj)

    if not gdf_alertas_proj.empty and not gdf_cnuc_proj.empty:
        alerts_in_ucs = gpd.sjoin(gdf_alertas_proj, gdf_cnuc_proj, how="inner", predicate="intersects")
    else:
        alerts_in_ucs = gpd.GeoDataFrame()


    if alerts_in_ucs.empty:
         return go.Figure() 

    alert_area_per_uc = alerts_in_ucs.groupby('nome_uc', observed=False)['AREAHA'].sum().reset_index()
    alert_area_per_uc.columns = ['nome_uc', 'alerta_ha_total'] 

    alert_area_per_uc = alert_area_per_uc.sort_values('alerta_ha_total', ascending=False)

    alert_area_per_uc['uc_wrap'] = alert_area_per_uc['nome_uc'].apply(lambda x: wrap_label(x, 15)) 

    fig = px.bar(
        alert_area_per_uc,
        x='uc_wrap',
        y='alerta_ha_total',
        labels={"alerta_ha_total":"√Årea de Alertas (ha)","uc_wrap":"UC"},
        text_auto=True,
    )

    fig.update_traces(
        customdata=np.stack([alert_area_per_uc.alerta_ha_total, alert_area_per_uc.nome_uc], axis=-1),
        hovertemplate=(
            "<b>%{customdata[1]}</b><br>"
            "√Årea de Alertas: %{customdata[0]:,.0f} ha<extra></extra>" 
        ),
        texttemplate="%{y:,.0f}", 
        textposition="outside", 
        marker_line_color="rgb(80,80,80)",
        marker_line_width=0.5,
    )

    media = alert_area_per_uc["alerta_ha_total"].mean()
    fig.add_shape(
        type="line", x0=-0.5, x1=len(alert_area_per_uc["uc_wrap"])-0.5,
        y0=media, y1=media,
        line=dict(color="FireBrick", width=2, dash="dash"),
    )
    fig.add_annotation(
        x=len(alert_area_per_uc["uc_wrap"])-0.5, y=media,
        text=f"M√©dia = {media:,.0f} ha", 
        showarrow=False, yshift=10,
        font=dict(color="FireBrick", size=10)
    )

    fig.update_xaxes(tickangle=0, tickfont=dict(size=9), title_text="")
    fig.update_yaxes(title_text="√Årea (ha)", tickfont=dict(size=9))
    fig.update_layout(height=400) 

    fig = _apply_layout(fig, title="√Årea de Alertas (Desmatamento) por UC", title_size=16)

    return fig

def fig_desmatamento_temporal(gdf_alertas_filtered: gpd.GeoDataFrame) -> go.Figure:
    """Cria um gr√°fico de linha mostrando a evolu√ß√£o temporal da √°rea de alertas de desmatamento."""
    if gdf_alertas_filtered.empty or 'DATADETEC' not in gdf_alertas_filtered.columns:
        fig = go.Figure()
        fig.update_layout(title="Evolu√ß√£o Temporal de Alertas (Desmatamento)",
                          xaxis_title="Data", yaxis_title="√Årea (ha)")
        return _apply_layout(fig, title="Evolu√ß√£o Temporal de Alertas (Desmatamento)", title_size=16)

    gdf_alertas_filtered['DATADETEC'] = pd.to_datetime(gdf_alertas_filtered['DATADETEC'], errors='coerce')
    gdf_alertas_filtered['AREAHA'] = pd.to_numeric(gdf_alertas_filtered['AREAHA'], errors='coerce')

    df_valid_dates = gdf_alertas_filtered.dropna(subset=['DATADETEC', 'AREAHA'])

    if df_valid_dates.empty:
         fig = go.Figure()
         fig.update_layout(title="Evolu√ß√£o Temporal de Alertas (Desmatamento)",
                          xaxis_title="Data", yaxis_title="√Årea (ha)")
         return _apply_layout(fig, title="Evolu√ß√£o Temporal de Alertas (Desmatamento)", title_size=16)

    df_monthly = df_valid_dates.set_index('DATADETEC').resample('ME')['AREAHA'].sum().reset_index()
    df_monthly['DATADETEC'] = df_monthly['DATADETEC'].dt.to_period('M').astype(str)

    fig = px.line(
        df_monthly,
        x='DATADETEC',
        y='AREAHA',
        labels={"AREAHA":"√Årea (ha)","DATADETEC":"M√™s/Ano"},
        markers=True,
        text='AREAHA'
    )

    fig.update_traces(
        mode='lines+markers+text',
        textposition='top center',
        texttemplate='%{text:,.0f}',
        hovertemplate=(
            "M√™s/Ano: %{x}<br>"
            "√Årea de Alertas: %{y:,.0f} ha<extra></extra>"
        )
    )

    fig.update_xaxes(title_text="M√™s/Ano", tickangle=45)
    fig.update_yaxes(title_text="√Årea (ha)")
    fig.update_layout(height=400)

    fig = _apply_layout(fig, title="Evolu√ß√£o Mensal de Alertas (Desmatamento)", title_size=16)

    return fig

def fig_desmatamento_municipio(gdf_alertas_filtered: gpd.GeoDataFrame) -> go.Figure:
    """Cria um gr√°fico de barras mostrando a √°rea total de alertas de desmatamento por munic√≠pio."""
    if gdf_alertas_filtered.empty or 'MUNICIPIO' not in gdf_alertas_filtered.columns or 'AREAHA' not in gdf_alertas_filtered.columns:
        return go.Figure() # Return empty figure if essential columns are missing

    # Ensure AREAHA is numeric
    gdf_alertas_filtered['AREAHA'] = pd.to_numeric(gdf_alertas_filtered['AREAHA'], errors='coerce').fillna(0)

    df_agg = gdf_alertas_filtered.groupby('MUNICIPIO', observed=False)['AREAHA'].sum().reset_index()
    df_agg = df_agg.sort_values('AREAHA', ascending=False)
   
    # Limit to top N municipalities if it's too crowded, e.g., top 30
    # df_agg = df_agg.head(30) # Optional: if the list is too long

    if df_agg.empty: # Check if aggregation resulted in an empty DataFrame
        return go.Figure()

    fig = px.bar(
        df_agg, # Use aggregated data
        x='AREAHA',
        y='MUNICIPIO',
        orientation='h',
        text='AREAHA',
        labels={'AREAHA': '√Årea Total Desmatada (ha)', 'MUNICIPIO': 'Munic√≠pio'} # Updated labels
    )
    fig = _apply_layout(fig, title="Desmatamento Total por Munic√≠pio") # Updated title

    fig.update_layout(
        yaxis=dict(autorange="reversed"), # Keep if you want largest bar on top
        xaxis=dict(
            tickformat=',.0f' # Format as integer or with fewer decimals if preferred
        ),
        margin=dict(l=150, r=40, t=50, b=20) # Adjust margins if y-axis labels are long
    )

    fig.update_traces(
        texttemplate='%{text:,.0f}', # Format text on bars
        textposition='outside',
        cliponaxis=False,                 
        marker_line_color='rgb(80,80,80)',
        marker_line_width=0.5
    )

    return fig

def fig_desmatamento_mapa_pontos(gdf_alertas_filtered: gpd.GeoDataFrame) -> go.Figure:
    """Cria um mapa de dispers√£o dos alertas de desmatamento."""
    if gdf_alertas_filtered.empty or 'AREAHA' not in gdf_alertas_filtered.columns or 'geometry' not in gdf_alertas_filtered.columns:
        fig = go.Figure()
        fig.update_layout(title="Mapa de Alertas (Desmatamento)")
        return _apply_layout(fig, title="Mapa de Alertas (Desmatamento)", title_size=16)

    gdf_alertas_filtered['AREAHA'] = pd.to_numeric(gdf_alertas_filtered['AREAHA'], errors='coerce')

    try:
        gdf_proj = gdf_alertas_filtered.to_crs("EPSG:31983").copy()
        centroids_proj = gdf_proj.geometry.centroid
        centroids_geo = centroids_proj.to_crs("EPSG:4326")

        gdf_map = gdf_alertas_filtered.to_crs("EPSG:4326").copy()
        gdf_map['Latitude'] = centroids_geo.y
        gdf_map['Longitude'] = centroids_geo.x

    except Exception as e:
        st.warning(f"Could not calculate or reproject centroids for map: {e}. Skipping map.")
        fig = go.Figure()
        fig.update_layout(title="Mapa de Alertas (Desmatamento)")
        return _apply_layout(fig, title="Mapa de Alertas (Desmatamento)", title_size=16)

    gdf_map = gdf_map.dropna(subset=['Latitude', 'Longitude'])

    if gdf_map.empty:
        fig = go.Figure()
        fig.update_layout(title="Mapa de Alertas (Desmatamento)")
        return _apply_layout(fig, title="Mapa de Alertas (Desmatamento)", title_size=16)

    minx, miny, maxx, maxy = gdf_map.total_bounds
    center = {'lat': (miny + maxy) / 2, 'lon': (minx + maxx) / 2}
    span_lat = maxy - miny
    lon_range = maxx - minx
    max_range = max(span_lat, lon_range, 0.01)

    zoom_level = 3.5
    if max_range < 0.1: zoom_level = 10
    elif max_range < 0.5: zoom_level = 8
    elif max_range < 1: zoom_level = 7
    elif max_range < 5: zoom_level = 5
    elif max_range < 10: zoom_level = 4
    elif max_range < 20: zoom_level = 3.5
    zoom_level = int(round(zoom_level))

    sample_size = 50000
    if len(gdf_map) > sample_size:
        gdf_map_plot = gdf_map.sample(sample_size, random_state=1)
    else:
        gdf_map_plot = gdf_map

    if gdf_map_plot.empty:
        fig = go.Figure()
        fig.update_layout(title="Mapa de Alertas (Desmatamento)")
        return _apply_layout(fig, title="Mapa de Alertas (Desmatamento)", title_size=16)

    fig = px.scatter_map(
        gdf_map_plot,
        lat='Latitude',
        lon='Longitude',
        size='AREAHA',
        color='AREAHA',
        color_continuous_scale="Reds",
        range_color=(0, gdf_map_plot['AREAHA'].quantile(0.95)),
        hover_name='CODEALERTA',
        hover_data={
            'AREAHA': ':.2f ha',
            'MUNICIPIO': True if 'MUNICIPIO' in gdf_map_plot.columns else False,
            'DATADETEC': True if 'DATADETEC' in gdf_map_plot.columns else False,
            'Latitude': False,
            'Longitude': False
        },
        size_max=15,
        zoom=zoom_level,
        center=center,
        opacity=0.7,
        map_style='open-street-map' 
    )

    fig.update_traces(showlegend=False)
    fig.update_coloraxes(showscale=False, colorbar=dict(title="√Årea (ha)")) 

    fig.update_layout(
        mapbox=dict(
            style='open-street-map',
            zoom=zoom_level,
            center=center
        ),
        margin={"r":0,"t":0,"l":0,"b":0},
        hovermode='closest'
    )
    
    fig.update_mapboxes(style='open-street-map')

    fig = _apply_layout(fig, title="Distribui√ß√£o Espacial de Alertas (Desmatamento)", title_size=16)

    return fig

import gc
import psycopg2
from psycopg2 import Error
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
import warnings

warnings.filterwarnings('ignore')
logging.getLogger().setLevel(logging.ERROR)

try:
    CONFIGURACAO_BANCO_DADOS = {
        'host': st.secrets.postgres.host,
        'database': st.secrets.postgres.database,
        'user': st.secrets.postgres.user,
        'password': st.secrets.postgres.password,
        'port': str(st.secrets.postgres.port), 
        'schema': st.secrets.postgres.esquema, # Assuming 'esquema' is the Portuguese for schema in secrets
        'table': st.secrets.postgres.table 
    }
except Exception as e: 
    st.error(f"Erro ao carregar configura√ß√£o do banco de dados dos secrets: {e}. Verifique o arquivo secrets.toml.")
    CONFIGURACAO_BANCO_DADOS = {} 

CHUNK_SIZE = 15000 
MEMORY_THRESHOLD = 85  

class GerenciadorBancoDados:
    def __init__(self, config): 
        self.config = config
        self._engine = None
        if self.config: 
            self._connection_string = self.construir_string_conexao()
        else:
            self._connection_string = None 

    def construir_string_conexao(self) -> str:
        if not self.config or not all(k in self.config for k in ['user', 'password', 'host', 'port', 'database']): return "" 
        return (f"postgresql://{self.config['user']}:{self.config['password']}"
                f"@{self.config['host']}:{self.config['port']}/{self.config['database']}")
    
    def obter_engine(self):
        if not self.config or not self._connection_string: 
            return None
        if self._engine is None:
            try:
                self._engine = create_engine(
                    self._connection_string,
                    pool_size=5, max_overflow=10, pool_pre_ping=True,
                    pool_recycle=3600, echo=False
                )
            except Exception as e:
                # Optionally log e
                self._engine = None 
                return None
        return self._engine
    
    def descartar(self):
        if self._engine:
            self._engine.dispose()
            self._engine = None

class ProcessadorDadosINPE:

    def __init__(self):
        self.gerenciador_bd = GerenciadorBancoDados(CONFIGURACAO_BANCO_DADOS) 
        self._base_filters = [ 
            "riscofogo BETWEEN 0 AND 1",
            "precipitacao >= 0",
            "diasemchuva >= 0",
            "latitude BETWEEN -15 AND 5",
            "longitude BETWEEN -60 AND -45"
        ]

    def verificar_uso_memoria(self) -> bool:
        return psutil.virtual_memory().percent < MEMORY_THRESHOLD

    def _otimizar_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        if df.empty:
            return df
        
        float_cols = df.select_dtypes(include=['float64']).columns
        for col in float_cols:
            df[col] = pd.to_numeric(df[col], downcast='float', errors='coerce')
        
        int_cols = df.select_dtypes(include=['int64']).columns
        for col in int_cols:
            df[col] = pd.to_numeric(df[col], downcast='integer', errors='coerce')
        
        obj_cols = df.select_dtypes(include=['object']).columns
        for col in obj_cols:
            if col != 'DataHora' and df[col].nunique() / len(df) < 0.4:
                df[col] = df[col].astype('category')
        
        gc.collect()
        return df

    def pegar_contagem_linhas(self, engine, where_clause: str) -> int:
        if not CONFIGURACAO_BANCO_DADOS or 'schema' not in CONFIGURACAO_BANCO_DADOS or 'table' not in CONFIGURACAO_BANCO_DADOS: return 0
        try:
            count_query = text(f"""
                SELECT COUNT(*) 
                FROM "{CONFIGURACAO_BANCO_DADOS['schema']}"."{CONFIGURACAO_BANCO_DADOS['table']}"
                WHERE {where_clause}
            """)
            
            with engine.connect() as conn:
                result = conn.execute(count_query)
                return result.scalar() or 0
        except Exception:
            return 0

    def construir_consulta_base(self) -> str:
        if not CONFIGURACAO_BANCO_DADOS or 'schema' not in CONFIGURACAO_BANCO_DADOS or 'table' not in CONFIGURACAO_BANCO_DADOS: return ""
        return f"""
            SELECT
                datahora,
                riscofogo,
                precipitacao,
                mun_corrigido,
                diasemchuva,
                latitude,
                longitude
            FROM "{CONFIGURACAO_BANCO_DADOS['schema']}"."{CONFIGURACAO_BANCO_DADOS['table']}"
        """

    def carregar_dados(self, engine, base_query: str, where_clause: str,
                       total_rows: int) -> Optional[pd.DataFrame]:
        chunks = []
        
        try:
            for offset in range(0, total_rows, CHUNK_SIZE):
                if not self.verificar_uso_memoria():
                    gc.collect()
                    if not self.verificar_uso_memoria():
                        break
                
                chunk_query = text(f"""
                    {base_query}
                    WHERE {where_clause}
                    LIMIT {CHUNK_SIZE} OFFSET {offset}
                """)
                
                chunk_df = pd.read_sql(chunk_query, engine, parse_dates=['datahora'])
                chunk_df = self._optimize_dataframe(chunk_df)
                chunks.append(chunk_df)
                
                del chunk_df
                gc.collect()
            
            if chunks:
                df = pd.concat(chunks, ignore_index=True)
                del chunks
                gc.collect()
                return df
            
        except Exception:
            pass
        
        return None

    def carregar_dados_inpe(self, year: Optional[int] = None) -> Optional[pd.DataFrame]:
        engine = self.gerenciador_bd.obter_engine()
        if not engine:
            st.error("Falha ao obter o motor do banco de dados. Verifique a configura√ß√£o.")
            return pd.DataFrame() # Return empty DataFrame on engine failure
        
        df = None # Initialize df
        try:
            filters = self._base_filters.copy()
            if year is not None:
                filters.append(f"EXTRACT(YEAR FROM datahora) = {year}")
            where_clause = " AND ".join(filters)

            total_rows = self.pegar_contagem_linhas(engine, where_clause)
            if total_rows == 0:
                return pd.DataFrame()

            base_query = self.construir_consulta_base()

            if total_rows <= CHUNK_SIZE:
                query = text(f"{base_query} WHERE {where_clause}")
                df = pd.read_sql(query, engine, parse_dates=['datahora'])
            else:
                df = self.carregar_dados(engine, base_query, where_clause, total_rows)

            if df is None or df.empty:
                return pd.DataFrame()
            
            df = df.rename(columns={
                'datahora': 'DataHora',
                'riscofogo': 'RiscoFogo',
                'precipitacao': 'Precipitacao',
                'mun_corrigido': 'mun_corrigido',
                'diasemchuva': 'DiaSemChuva',
                'latitude': 'Latitude',
                'longitude': 'Longitude'
            })

            df = self._otimizar_dataframe(df)
            df = df.dropna(subset=['DataHora', 'mun_corrigido'])
            
            gc.collect() # Collect after processing df
            return df
            
        except Exception:
            # Log error (st.error or logging could be added here if not present)
            gc.collect() # Collect even on exception
            return pd.DataFrame() # Return empty DataFrame on exception
        finally:
            self.gerenciador_bd.descartar()
            gc.collect() # Ensure collection after engine disposal

    def pegar_anos_disponiveis(self) -> List[int]:
        engine = self.gerenciador_bd.obter_engine()
        if not engine:
            st.error("Falha ao obter o motor do banco de dados para buscar anos. Verifique a configura√ß√£o.")
            return []
        
        if not CONFIGURACAO_BANCO_DADOS or 'schema' not in CONFIGURACAO_BANCO_DADOS or 'table' not in CONFIGURACAO_BANCO_DADOS:
            st.error("Configura√ß√£o do banco de dados incompleta para buscar anos.")
            return []
            
        try:
            query = text(f"""
                SELECT DISTINCT EXTRACT(YEAR FROM datahora) AS year
                FROM "{CONFIGURACAO_BANCO_DADOS['schema']}"."{CONFIGURACAO_BANCO_DADOS['table']}"
                WHERE datahora IS NOT NULL
                ORDER BY year
            """)
            
            with engine.connect() as conn:
                result = conn.execute(query)
                years = [int(row[0]) for row in result.fetchall() if row[0] is not None]
            
            gc.collect()
            return years
            
        except Exception:
            gc.collect()
            return []
        finally:
            self.gerenciador_bd.descartar()
            gc.collect()

class processarRanking:
    
    @staticmethod
    def processar_chunk(chunk: pd.DataFrame, theme: str) -> pd.DataFrame:
        chunk_clean = chunk.dropna(subset=['mun_corrigido']).copy()
        
        agg_configs = {
            "Maior Risco de Fogo": {
                'RiscoFogo': ['mean', 'max', 'count'],
                'DataHora': ['min', 'max']
            },
            "Maior Precipita√ß√£o (evento)": {
                'Precipitacao': ['mean', 'max', 'sum', 'count'],
                'DataHora': ['min', 'max']
            },
            "M√°x. Dias Sem Chuva": {
                'DiaSemChuva': ['mean', 'max', 'count'],
                'DataHora': ['min', 'max']
            }
        }
        
        if theme in agg_configs:
            return chunk_clean.groupby('mun_corrigido', observed=True).agg(agg_configs[theme])
        
        return pd.DataFrame()
    
    @staticmethod
    def combinar_resultados(results: List[pd.DataFrame], theme: str) -> pd.DataFrame:
        if not results:
            return pd.DataFrame()
        
        combine_configs = {
            "Maior Risco de Fogo": {
                ('RiscoFogo', 'mean'): 'mean',
                ('RiscoFogo', 'max'): 'max',
                ('RiscoFogo', 'count'): 'sum',
                ('DataHora', 'min'): 'min',
                ('DataHora', 'max'): 'max'
            },
            "Maior Precipita√ß√£o (evento)": {
                ('Precipitacao', 'mean'): 'mean',
                ('Precipitacao', 'max'): 'max',
                ('Precipitacao', 'sum'): 'sum',
                ('Precipitacao', 'count'): 'sum',
                ('DataHora', 'min'): 'min',
                ('DataHora', 'max'): 'max'
            },
            "M√°x. Dias Sem Chuva": {
                ('DiaSemChuva', 'mean'): 'mean',
                ('DiaSemChuva', 'max'): 'max',
                ('DiaSemChuva', 'count'): 'sum',
                ('DataHora', 'min'): 'min',
                ('DataHora', 'max'): 'max'
            }
        }
        
        if theme in combine_configs:
            return pd.concat(results).groupby(level=0, observed=True).agg(combine_configs[theme])
        
        return pd.DataFrame()
    
    @staticmethod
    def resultado_ranking(df_agg: pd.DataFrame, theme: str) -> Tuple[pd.DataFrame, str]:
        if df_agg.empty:
            return pd.DataFrame(), ''
        
        formatters = {
            "Maior Risco de Fogo": (
                processarRanking._format_fire_risk_ranking,
                'Risco M√©dio'
            ),
            "Maior Precipita√ß√£o (evento)": (
                processarRanking._format_precipitation_ranking,
                'Precipita√ß√£o M√°xima (mm)'
            ),
            "M√°x. Dias Sem Chuva": (
                processarRanking._format_dry_days_ranking,
                'M√°x. Dias Sem Chuva'
            )
        }
        
        if theme in formatters:
            formatter_func, col_name = formatters[theme]
            df_rank = formatter_func(df_agg)
            
            if not df_rank.empty:
                df_rank.insert(0, 'Posi√ß√£o', range(1, len(df_rank) + 1))
            
            return df_rank, col_name
        
        return pd.DataFrame(), ''
    
    @staticmethod
    def risco_fogo_ranking(df_agg: pd.DataFrame) -> pd.DataFrame:
        df_agg = df_agg.round(4)
        df_rank = df_agg.nlargest(20, ('RiscoFogo', 'mean')).reset_index()
        
        df_rank.columns = ['Munic√≠pio', 'Risco M√©dio', 'Risco M√°ximo', 'N¬∫ Registros', 
                           'Primeira Ocorr√™ncia', '√öltima Ocorr√™ncia']
        
        df_rank['Primeira Ocorr√™ncia'] = pd.to_datetime(df_rank['Primeira Ocorr√™ncia']).dt.strftime('%d/%m/%Y')
        df_rank['√öltima Ocorr√™ncia'] = pd.to_datetime(df_rank['√öltima Ocorr√™ncia']).dt.strftime('%d/%m/%Y')
        
        return df_rank
    
    @staticmethod
    def precipita√ß√£o_ranking(df_agg: pd.DataFrame) -> pd.DataFrame:
        df_agg = df_agg.round(2)
        df_rank = df_agg.nlargest(20, ('Precipitacao', 'max')).reset_index()
        
        df_rank.columns = ['Munic√≠pio', 'Precipita√ß√£o M√°xima (mm)', 'Precipita√ß√£o M√©dia (mm)',
                           'Precipita√ß√£o Total (mm)', 'N¬∫ Registros', 'Primeira Ocorr√™ncia', 
                           '√öltima Ocorr√™ncia']
        
        df_rank['Primeira Ocorr√™ncia'] = pd.to_datetime(df_rank['Primeira Ocorr√™ncia']).dt.strftime('%d/%m/%Y')
        df_rank['√öltima Ocorr√™ncia'] = pd.to_datetime(df_rank['√öltima Ocorr√™ncia']).dt.strftime('%d/%m/%Y')
        
        return df_rank
    
    @staticmethod
    def dias_sem_chuva_ranking(df_agg: pd.DataFrame) -> pd.DataFrame:
        df_agg = df_agg.round(1)
        df_rank = df_agg.nlargest(20, ('DiaSemChuva', 'max')).reset_index()
        
        df_rank.columns = ['Munic√≠pio', 'M√°x. Dias Sem Chuva', 'M√©dia Dias Sem Chuva',
                           'N¬∫ Registros', 'Primeira Ocorr√™ncia', '√öltima Ocorr√™ncia']
        
        df_rank['Primeira Ocorr√™ncia'] = pd.to_datetime(df_rank['Primeira Ocorr√™ncia']).dt.strftime('%d/%m/%Y')
        df_rank['√öltima Ocorr√™ncia'] = pd.to_datetime(df_rank['√öltima Ocorr√™ncia']).dt.strftime('%d/%m/%Y')
        
        return df_rank

    def processar_ranking(self, df: pd.DataFrame, theme: str, period: str) -> Tuple[pd.DataFrame, str]:
        if df is None or df.empty:
            return pd.DataFrame(), ''
        
        try:
            if len(df) > CHUNK_SIZE:
                chunks = [df[i:i + CHUNK_SIZE] for i in range(0, len(df), CHUNK_SIZE)]
                results = []
                
                for chunk in chunks:
                    chunk_result = self.processar_chunk(chunk, theme)
                    if not chunk_result.empty:
                        results.append(chunk_result)
                    
                    del chunk
                    gc.collect()

                df_agg = self.combinar_resultados(results, theme)
                del results
                gc.collect()
            else:
                df_agg = self.processar_chunk(df, theme)

            df_rank, col_ord = self.resultado_ranking(df_agg, theme)

            del df_agg
            gc.collect()
            
            return df_rank, col_ord
            
        except Exception:
            return pd.DataFrame(), ''

@st.cache_data(ttl=1800, show_spinner=False, max_entries=3)  
def obter_dados_queimadas_cache(year: Optional[int] = None) -> Optional[pd.DataFrame]:
    processor = ProcessadorDadosINPE()
    return processor.carregar_dados_inpe(year)

@st.cache_data(ttl=3600, show_spinner=False, max_entries=1) 
def obter_anos_disponiveis_cache() -> List[int]:
    processor = ProcessadorDadosINPE()
    return processor.pegar_anos_disponiveis()

@st.cache_data(ttl=900, show_spinner=False, max_entries=3) 
def obter_ranking_cache(df_hash: str, theme: str, period: str) -> Tuple[pd.DataFrame, str]:
    parts = df_hash.split('_')
    if len(parts) >= 2:
        year_option = parts[0]
        
        if year_option == "Todos":
            df = obter_dados_queimadas_cache(None)
        else:
            try:
                year = int(year_option)
                df = obter_dados_queimadas_cache(year)
            except ValueError:
                df = obter_dados_queimadas_cache(None)
    else:
        df = obter_dados_queimadas_cache(None)

    if df is None: # df can be None if db connection fails
        return pd.DataFrame(), ''

    processor = processarRanking() # Assuming processarRanking does not need CONFIGURACAO_BANCO_DADOS directly
    return processor.processar_ranking(df, theme, period)

def inicializar_dados_queimadas() -> Tuple[List[str], pd.DataFrame]:
    opcoes_ano = ["Todos os Anos"] # Default
    df_base = pd.DataFrame()      # Default
    try:
        anos = obter_anos_disponiveis_cache() # Returns [] on error
        opcoes_ano = ["Todos os Anos"] + [str(ano) for ano in anos]
        
        ano_mais_recente = None
        if anos:
            ano_mais_recente = max(anos)
        
        # obter_dados_queimadas_cache now always returns a DataFrame
        # If it's empty and an error occurred, st.error was already called.
        df_base = obter_dados_queimadas_cache(ano_mais_recente) 
        
        return opcoes_ano, df_base
    except Exception as e:
        # This catch-all is if obter_anos_disponiveis_cache or obter_dados_queimadas_cache themselves raise an unexpected error
        st.error(f"Erro inesperado ao inicializar dados da aba Queimadas: {e}")
        return opcoes_ano, df_base # Return defaults

def obter_dados_queimadas_por_ano(opcao_ano: str, df_base_atual: pd.DataFrame) -> pd.DataFrame:
    dados_para_ano = pd.DataFrame() # Default to empty
    try:
        if opcao_ano == "Todos os Anos":
            dados_para_ano = obter_dados_queimadas_cache(None)
        else:
            year = int(opcao_ano)
            year_in_base_df = None
            if not df_base_atual.empty and 'DataHora' in df_base_atual.columns:
                if not pd.api.types.is_datetime64_any_dtype(df_base_atual['DataHora']):
                    df_base_atual['DataHora'] = pd.to_datetime(df_base_atual['DataHora'], errors='coerce')
                if not df_base_atual.empty and not df_base_atual['DataHora'].dropna().empty:
                    year_in_base_df = df_base_atual['DataHora'].dropna().iloc[0].year
            
            if year == year_in_base_df:
                dados_para_ano = df_base_atual
            else:
                dados_para_ano = obter_dados_queimadas_cache(year)
        
        # If an error occurred in cache, it would have displayed st.error and returned empty df
        return dados_para_ano if dados_para_ano is not None else pd.DataFrame()

    except ValueError: # For int(opcao_ano)
        st.error(f"Op√ß√£o de ano inv√°lida: {opcao_ano}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"Erro inesperado ao obter dados de queimadas por ano: {e}")
        return pd.DataFrame()

def renderizar_aba_queimadas():
    if not CONFIGURACAO_BANCO_DADOS or not CONFIGURACAO_BANCO_DADOS.get('host'): # Check if essential keys are missing
        st.error("A configura√ß√£o do banco de dados para a aba Queimadas n√£o foi carregada corretamente. Verifique os secrets.")
        return 

    ANO_OPCOES, DF_BASE_QUEIMADAS = inicializar_dados_queimadas()
    
    st.header("Focos de Calor")
    
    # Section for Graphs
    st.subheader("Visualiza√ß√£o Gr√°fica dos Focos de Calor")
    ano_sel_graf = st.selectbox(
        'Selecione o per√≠odo para os gr√°ficos:',
        ANO_OPCOES,
        index=0, 
        key="ano_focos_calor_graficos_key"
    )
    df_para_graficos = obter_dados_queimadas_por_ano(ano_sel_graf, DF_BASE_QUEIMADAS)

    if df_para_graficos.empty:
        # This message is shown if data loading was successful but no data points for the selection,
        # OR if data loading failed (in which case an st.error would have already been shown by lower functions).
        st.info(f"Nenhum dado de queimadas dispon√≠vel para visualiza√ß√£o gr√°fica para o per√≠odo: {ano_sel_graf}.")
    else:
        ano_param_graf = None if ano_sel_graf == "Todos os Anos" else int(ano_sel_graf)
        display_periodo_graf = ("todo o per√≠odo hist√≥rico" if ano_param_graf is None else f"o ano de {ano_param_graf}")
        
        figs = graficos_inpe(df_para_graficos, ano_sel_graf) # graficos_inpe should handle its own empty df if it happens
        
        st.subheader(f"Evolu√ß√£o Temporal do Risco de Fogo ({display_periodo_graf})")
        st.plotly_chart(figs['temporal'], use_container_width=True)
        # st.caption(f"Figura: Evolu√ß√£o mensal do risco m√©dio de fogo para {display_periodo_graf}.") # Caption can be made more concise or part of title

        col1_figs, col2_figs = st.columns(2, gap="large")
        with col1_figs:
            st.subheader(f"Top Munic√≠pios - Risco de Fogo ({display_periodo_graf})")
            st.plotly_chart(figs['top_risco'], use_container_width=True)
            st.subheader(f"Top Munic√≠pios - Precipita√ß√£o ({display_periodo_graf})")
            st.plotly_chart(figs['top_precip'], use_container_width=True)
        with col2_figs:
            st.subheader(f"Mapa de Distribui√ß√£o dos Focos ({display_periodo_graf})")
            st.plotly_chart(figs['mapa'], use_container_width=True, config={'scrollZoom': True})

    st.divider()
    st.header("Ranking de Munic√≠pios por Indicadores de Queimadas")
    
    # Section for Ranking - uses its own year selector for clarity or could reuse ano_sel_graf
    colA_rank, colB_rank = st.columns(2)
    with colA_rank:
        ano_sel_rank = st.selectbox(
            'Selecione o per√≠odo para o ranking:',
            ANO_OPCOES,
            index=0, 
            key="ano_focos_calor_ranking_key" # Unique key for ranking year selection
        )
    with colB_rank:
        tema_rank_val = st.selectbox(
            'Indicador para ranking:',
            ["Maior Risco de Fogo", "Maior Precipita√ß√£o (evento)", "M√°x. Dias Sem Chuva"],
            key="tema_ranking_queimadas_key" # Unique key
        )

    df_para_ranking = obter_dados_queimadas_por_ano(ano_sel_rank, DF_BASE_QUEIMADAS)
    
    if df_para_ranking.empty:
        st.info(f"Dados insuficientes para gerar o ranking de '{tema_rank_val}' para o per√≠odo: {ano_sel_rank}.")
    else:
        rank_hash_val = f"{ano_sel_rank}_{tema_rank_val}_{len(df_para_ranking)}"
        periodo_rank_val = "Todo o Per√≠odo Hist√≥rico" if ano_sel_rank == "Todos os Anos" else f"Ano de {ano_sel_rank}"
        
        st.subheader(f"Ranking por {tema_rank_val} ({periodo_rank_val})")
        df_rank_result, _ = obter_ranking_cache(rank_hash_val, tema_rank_val, periodo_rank_val)

        if not df_rank_result.empty:
            st.dataframe(df_rank_result, use_container_width=True, hide_index=True)
        else:
            # This message covers cases where ranking processing itself results in empty (e.g. no valid data after agg)
            # or if obter_ranking_cache had an issue not already caught by st.error.
            st.info(f"N√£o foi poss√≠vel gerar o ranking de '{tema_rank_val}' para o per√≠odo: {ano_sel_rank}.")

gdf_alertas_cols = ['geometry', 'MUNICIPIO', 'AREAHA', 'ANODETEC', 'DATADETEC', 'CODEALERTA', 'ESTADO', 'BIOMA', 'VPRESSAO']
gdf_cnuc_cols = ['geometry', 'nome_uc', 'municipio', 'alerta_km2', 'sigef_km2', 'area_km2', 'c_alertas', 'c_sigef', 'ha_total'] 
gdf_sigef_cols = ['geometry', 'municipio', 'area_km2', 'invadindo']
df_csv_cols = ["Unnamed: 0", "√Åreas de conflitos", "Assassinatos", "Conflitos por Terra", "Ocupa√ß√µes Retomadas", "Tentativas de Assassinatos", "Trabalho Escravo", "Latitude", "Longitude"]
df_proc_cols = ['numero_processo', 'data_ajuizamento', 'municipio', 'classe', 'assuntos', 'orgao_julgador', 'ultima_atualiza√ßao']


gdf_alertas_raw = carregar_shapefile(
    r"alertas.shp",
    calcular_percentuais=False,
    columns=gdf_alertas_cols
)
gdf_alertas_raw = gdf_alertas_raw.rename(columns={"id":"id_alerta"})

gdf_cnuc_raw = carregar_shapefile(
    r"cnuc.shp",
    columns=gdf_cnuc_cols
)
if 'ha_total' not in gdf_cnuc_raw.columns:
    gdf_cnuc_raw['ha_total'] = gdf_cnuc_raw.get('area_km2', 0) * 100
    gdf_cnuc_raw['ha_total'] = pd.to_numeric(gdf_cnuc_raw['ha_total'], downcast='float', errors='coerce')

gdf_cnuc_ha_raw = preparar_hectares(gdf_cnuc_raw)

gdf_sigef_raw = carregar_shapefile(
    r"sigef.shp",
    calcular_percentuais=False,
    columns=gdf_sigef_cols
)
gdf_sigef_raw   = gdf_sigef_raw.rename(columns={"id":"id_sigef"})

if 'MUNICIPIO' in gdf_sigef_raw.columns and 'municipio' not in gdf_sigef_raw.columns:
    gdf_sigef_raw = gdf_sigef_raw.rename(columns={'MUNICIPIO': 'municipio'})
elif 'municipio' not in gdf_sigef_raw.columns:
    st.warning("Coluna 'municipio' ou 'MUNICIPIO' n√£o encontrada em sigef.shp. Adicionando coluna placeholder.")
    gdf_sigef_raw['municipio'] = None 

limites = gdf_cnuc_raw.total_bounds
centro = {
    "lat": (limites[1] + limites[3]) / 2,
    "lon": (limites[0] + limites[2]) / 2
}

df_csv_raw = load_csv(
    r"CPT-PA-count.csv", 
    columns=df_csv_cols
)
# df_confmun_raw will be loaded inside Tab 1 (CPT)

@st.cache_data(persist="disk")
def load_df_proc(caminho: str, columns: list[str]) -> pd.DataFrame:
    df = pd.read_csv(caminho, sep=";", encoding="windows-1252", usecols=columns)
    for col in df.columns:
        if df[col].dtype == 'float64':
            df[col] = pd.to_numeric(df[col], downcast='float', errors='coerce')
        elif df[col].dtype == 'int64':
            df[col] = pd.to_numeric(df[col], downcast='integer', errors='coerce')
        elif df[col].dtype == 'object':
            if len(df[col].unique()) / len(df) < 0.5:
                 try:
                    df[col] = df[col].astype('category')
                 except Exception:
                    pass
    gc.collect()
    return df

# df_proc_raw will be loaded inside Tab 2 (Justi√ßa)

tabs = st.tabs(["Sobreposi√ß√µes", "CPT", "Justi√ßa", "Queimadas", "Desmatamento"])

with tabs[0]:
    st.header("Sobreposi√ß√µes")
    with st.expander("‚ÑπÔ∏è Sobre esta se√ß√£o", expanded=True):
        st.write("""
        Esta an√°lise apresenta dados sobre sobreposi√ß√µes territoriais, incluindo:
        - Percentuais de alertas e CARs sobre extens√£o territorial
        - Distribui√ß√£o por munic√≠pios
        - √Åreas e contagens por Unidade de Conserva√ß√£o
        
        Os dados s√£o provenientes do CNUC (Cadastro Nacional de Unidades de Conserva√ß√£o) e SIGEF (Sistema de Gest√£o Fundi√°ria).
        """)
        st.markdown(
            "**Fonte Geral da Se√ß√£o:** MMA - Minist√©rio do Meio Ambiente. Cadastro Nacional de Unidades de Conserva√ß√£o. Bras√≠lia: MMA.",
            unsafe_allow_html=True
               )

    perc_alerta, perc_sigef, total_unidades, contagem_alerta, contagem_sigef = criar_cards(gdf_cnuc_raw, gdf_sigef_raw, None)
    cols = st.columns(5, gap="small")
    titulos = [
        ("Alertas / Ext. Ter.", f"{perc_alerta:.1f}%", "√Årea de alertas sobre extens√£o territorial"),
        ("CARs / Ext. Ter.", f"{perc_sigef:.1f}%", "CARs sobre extens√£o territorial"),
        ("Munic√≠pios", f"{total_unidades}", "Total de munic√≠pios na an√°lise"),
        ("Alertas", f"{contagem_alerta}", "Total de registros de alertas"),
        ("CARs", f"{contagem_sigef}", "Cadastros Ambientais Rurais")
    ]
    card_template = """
    <div style="
        background-color:#F9F9FF;
        border:1px solid #E00E0;
        padding:1rem;
        border-radius:8px;
        box-shadow:0 2px 4px rgba(0,0,0,0.1);
        text-align:center;
        height:100px;
        display:flex;
        flex-direction:column;
        justify-content:center;">
        <h5 style="margin:0; font-size:0.9rem;">{0}</h5>
        <p style="margin:0; font-size:1.2rem; font-weight:bold; color:#2F5496;">{1}</p>
        <small style="color:#666;">{2}</small>
    </div>
    """
    for col, (t, v, d) in zip(cols, titulos):
        col.markdown(card_template.format(t, v, d), unsafe_allow_html=True)

    st.divider()

    row1_map, row1_chart1 = st.columns([3, 2], gap="large")
    with row1_map:
        opcoes_invadindo = ["Selecione", "Todos"] + sorted(gdf_sigef_raw["invadindo"].str.strip().unique().tolist())
        invadindo_opcao_temp = st.selectbox("Tipo de sobreposi√ß√£o:", opcoes_invadindo, index=0, help="Selecione o tipo de √°rea sobreposta para an√°lise")
        invadindo_opcao = None if invadindo_opcao_temp == "Selecione" else invadindo_opcao_temp
        gdf_cnuc_map = gdf_cnuc_raw.copy()
        gdf_sigef_map = gdf_sigef_raw.copy()
        ids_selecionados_map = []

        if invadindo_opcao and invadindo_opcao.lower() != "todos":
            sigef_filtered_for_sjoin = gdf_sigef_map[gdf_sigef_map["invadindo"].str.strip().str.lower() == invadindo_opcao.lower()]
            if not sigef_filtered_for_sjoin.empty:
                 gdf_cnuc_proj_sjoin = gdf_cnuc_map.to_crs(sigef_filtered_for_sjoin.crs)
                 gdf_filtrado_map = gpd.sjoin(gdf_cnuc_proj_sjoin, sigef_filtered_for_sjoin, how="inner", predicate="intersects")
                 ids_selecionados_map = gdf_filtrado_map["id"].unique().tolist()
            else:
                 ids_selecionados_map = [] 

        st.subheader("Mapa de Unidades")
        fig_map = criar_figura(gdf_cnuc_map, gdf_sigef_map, df_csv_raw, centro, ids_selecionados_map, invadindo_opcao)
        st.plotly_chart(
            fig_map,
            use_container_width=True,
            height=300,
            config={"scrollZoom": True}
        )
        st.caption("Figura 1.1: Distribui√ß√£o espacial das unidades de conserva√ß√£o.")
        with st.expander("Detalhes e Fonte da Figura 1.1"):
            st.write("""
            **Interpreta√ß√£o:**
            O mapa mostra a distribui√ß√£o espacial das unidades de conserva√ß√£o na regi√£o, destacando as √°reas com sobreposi√ß√µes selecionadas.

            **Observa√ß√µes:**
            - √Åreas em destaque indicam unidades de conserva√ß√£o
            - Cores diferentes representam diferentes tipos de unidades
            - Sobreposi√ß√µes s√£o destacadas quando selecionadas no filtro

            **Fonte:** MMA - Minist√©rio do Meio Ambiente. *Cadastro Nacional de Unidades de Conserva√ß√£o*. Bras√≠lia: MMA, 2025. Dispon√≠vel em: https://www.gov.br/mma/. Acesso em: maio de 2025.
            """)

        st.subheader("Propor√ß√£o da √Årea do CAR sobre a UC")
        uc_names = ["Todas"] + sorted(gdf_cnuc_ha_raw["nome_uc"].unique())
        nome_uc = st.selectbox("Selecione a Unidade de Conserva√ß√£o:", uc_names)
        modo_input = st.radio("Mostrar valores como:", ["Hectares (ha)", "% da UC"], horizontal=True)
        modo = "absoluto" if modo_input == "Hectares (ha)" else "percent"
        fig = fig_car_por_uc_donut(gdf_cnuc_ha_raw, nome_uc, modo)
        st.plotly_chart(fig, use_container_width=True)
        st.caption("Figura 1.2: Compara√ß√£o entre √°rea do CAR e √°rea restante da UC.")
        with st.expander("Detalhes e Fonte da Figura 1.2"):
            st.write("""
            **Interpreta√ß√£o:**
            Este gr√°fico mostra a propor√ß√£o entre a √°rea cadastrada no CAR e a √°rea restante da Unidade de Conserva√ß√£o (UC).

            **Observa√ß√µes:**
            - A √°rea restante √© o que sobra da UC ap√≥s considerar a √°rea cadastrada no CAR
            - Pode ocorrer de o CAR ultrapassar 100% devido a sobreposi√ß√µes ou m√∫ltiplos cadastros em uma mesma √°rea
            - Valores podem ser visualizados em hectares ou percentual, conforme sele√ß√£o acima

            **Fonte:** MMA - Minist√©rio do Meio Ambiente. *Cadastro Nacional de Unidades de Conserva√ß√£o*. Bras√≠lia: MMA, 2025. Dispon√≠vel em: https://www.gov.br/mma/. Acesso em: maio de 2025.
            """)

    with row1_chart1:
        st.subheader("√Åreas por UC")
        st.plotly_chart(fig_sobreposicoes(gdf_cnuc_ha_raw), use_container_width=True, height=350)
        st.caption("Figura 1.3: Distribui√ß√£o de √°reas por unidade de conserva√ß√£o.")
        with st.expander("Detalhes e Fonte da Figura 1.3"):
            st.write("""
            **Interpreta√ß√£o:**
            O gr√°fico apresenta a √°rea em hectares de cada unidade de conserva√ß√£o, permitindo comparar suas extens√µes territoriais.

            **Observa√ß√µes:**
            - Barras representam √°rea em hectares
            - Linha tracejada indica a m√©dia
            - Ordenado por tamanho da √°rea

            **Fonte:** MMA - Minist√©rio do Meio Ambiente. *Cadastro Nacional de Unidades de Conserva√ß√£o*. Bras√≠lia: MMA, 2025. Dispon√≠vel em: https://www.gov.br/mma/. Acesso em: maio de 2025.
            """)

        st.subheader("Contagens por UC")
        st.plotly_chart(fig_contagens_uc(gdf_cnuc_raw), use_container_width=True, height=350)
        st.caption("Figura 1.4: Contagem de sobreposi√ß√µes por unidade de conserva√ß√£o.")
        with st.expander("Detalhes e Fonte da Figura 1.4"):
            st.write("""
            **Interpreta√ß√£o:**
            O gr√°fico mostra o n√∫mero de alertas e CARs sobrepostos a cada unidade de conserva√ß√£o.

            **Observa√ß√µes:**
            - Barras empilhadas mostram alertas e CARs
            - Linha tracejada indica m√©dia total
            - Ordenado por total de sobreposi√ß√µes

            **Fonte:** MMA - Minist√©rio do Meio Ambiente. *Cadastro Nacional de Unidades de Conserva√ß√£o*. Bras√≠lia: MMA, 2025. Dispon√≠vel em: https://www.gov.br/mma/. Acesso em: maio de 2025.
            """)

    st.markdown("""<div style="background-color: #fff; border-radius: 6px; padding: 1.5rem; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 0.5rem;">
        <h3 style="color: #1E1E1E; margin-top: 0; margin-bottom: 0.5rem;">Tabela Unificada</h3>
        <p style="color: #666; font-size: 0.95em; margin-bottom:0;">Visualiza√ß√£o unificada dos dados de alertas, SIGEF e CNUC.</p>
    </div>""", unsafe_allow_html=True)
    mostrar_tabela_unificada(gdf_alertas_raw, gdf_sigef_raw, gdf_cnuc_raw)
    st.caption("Tabela 1.1: Dados consolidados por munic√≠pio.")
    with st.expander("Detalhes e Fonte da Tabela 1.1"):
        st.write("""
        **Interpreta√ß√£o:**
        A tabela apresenta os dados consolidados por munic√≠pio, incluindo:
        - √Årea de alertas em hectares
        - √Årea do SIGEF em hectares
        - √Årea do CNUC em hectares

        **Observa√ß√µes:**
        - Valores em hectares
        - Totais na √∫ltima linha
        - C√©lulas coloridas por tipo de dado

        **Fonte:** MMA - Minist√©rio do Meio Ambiente. *Cadastro Nacional de Unidades de Conserva√ß√£o*. Bras√≠lia: MMA, 2025. Dispon√≠vel em: https://www.gov.br/mma/. Acesso em: maio de 2025.
        """)
    st.divider()

with tabs[1]:
    st.header("Impacto Social")
    with st.expander("‚ÑπÔ∏è Sobre esta se√ß√£o", expanded=True):
        st.write("""
        Esta an√°lise apresenta dados sobre impactos sociais relacionados a conflitos agr√°rios, incluindo:
        - Fam√≠lias afetadas
        - Conflitos registrados
        - Ocupa√ß√µes retomadas

        Os dados s√£o provenientes da Comiss√£o Pastoral da Terra (CPT).
        """)
        st.markdown(
            "**Fonte Geral da Se√ß√£o:** CPT - Comiss√£o Pastoral da Terra. Conflitos no Campo Brasil. Goi√¢nia: CPT Nacional.",
            unsafe_allow_html=True
        )

    # Load df_confmun_raw here as it's specific to this tab
    df_confmun_raw = carregar_dados_conflitos_municipio(
        r"CPTF-PA.xlsx"
    )
    df_tabela_social = df_confmun_raw.copy()

    df_csv_cleaned = df_csv_raw.copy() # df_csv_raw is loaded globally
    if 'Munic√≠pio' in df_csv_cleaned.columns:
        df_csv_cleaned['Munic√≠pio'] = df_csv_cleaned['Munic√≠pio'].apply(lambda x: str(x).strip().title() if pd.notna(x) else None)

    if 'Munic√≠pio' in df_tabela_social.columns:
         df_tabela_social['Munic√≠pio'] = df_tabela_social['Munic√≠pio'].apply(lambda x: str(x).strip().title() if pd.notna(x) else None)

    csv_cols_to_merge = ['Munic√≠pio']
    if 'Ocupa√ß√µes Retomadas' in df_csv_cleaned.columns:
        csv_cols_to_merge.append('Ocupa√ß√µes Retomadas')

    if len(csv_cols_to_merge) > 1:
        df_csv_agg = df_csv_cleaned[csv_cols_to_merge].groupby('Munic√≠pio', observed=False).sum().reset_index()
        df_tabela_social = df_tabela_social.merge(df_csv_agg, on='Munic√≠pio', how='left').fillna(0)
    else:
        if 'Ocupa√ß√µes Retomadas' not in df_tabela_social.columns:
            df_tabela_social['Ocupa√ß√µes Retomadas'] = 0


    df_tabela_social = df_tabela_social.sort_values('Total_Fam√≠lias', ascending=False)

    df_display = df_tabela_social.rename(columns={
        'Munic√≠pio': 'Munic√≠pio',
        'Total_Fam√≠lias': 'Fam√≠lias Afetadas',
        'N√∫mero_Conflitos': 'Conflitos Registrados',
        'Ocupa√ß√µes Retomadas': 'Ocupa√ß√µes Retomadas'
    })

    display_cols = ['Munic√≠pio', 'Fam√≠lias Afetadas', 'Conflitos Registrados', 'Ocupa√ß√µes Retomadas']
    for col in display_cols:
        if col not in df_display.columns:
            df_display[col] = 0

    linha_total = pd.DataFrame({
        'Munic√≠pio': ['TOTAL'],
        'Fam√≠lias Afetadas': [df_display['Fam√≠lias Afetadas'].sum()],
        'Conflitos Registrados': [df_display['Conflitos Registrados'].sum()],
        'Ocupa√ß√µes Retomadas': [df_display['Ocupa√ß√µes Retomadas'].sum()]
    })
    df_display_com_total = pd.concat([df_display, linha_total], ignore_index=True)

    def aplicar_cor_social(val, col):
        if col == 'Munic√≠pio':
            return 'background-color: #f0f0f0' if val == 'TOTAL' else ''
        elif col == 'Fam√≠lias Afetadas':
            return 'background-color: #ffebee; font-weight: bold' if val == df_display_com_total[col].iloc[-1] else 'background-color: #ffebee'
        elif col == 'Conflitos Registrados':
            return 'background-color: #fff3e0; font-weight: bold' if val == df_display_com_total[col].iloc[-1] else 'background-color: #fff3e0'
        elif col == 'Ocupa√ß√µes Retomadas':
             return 'background-color: #e3f2fd; font-weight: bold' if val == df_display_com_total[col].iloc[-1] else 'background-color: #e3f2fd'
        return ''

    styled_df = df_display_com_total.style.apply(
        lambda x: [aplicar_cor_social(val, col) for val, col in zip(x, df_display_com_total.columns)],
        axis=1
    ).format({
        'Fam√≠lias Afetadas': '{:,.0f}',
        'Conflitos Registrados': '{:,.0f}',
        'Ocupa√ß√µes Retomadas': '{:,.0f}'
    })

    col_fam, col_conf = st.columns(2, gap="large")
    with col_fam:
        st.markdown("""<div style="background-color: #fff; border-radius: 6px; padding: 1.5rem; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 0.5rem;">
            <h3 style="color: #1E1E1E; margin-top: 0; margin-bottom: 0.5rem;">Fam√≠lias Afetadas</h3>
            <p style="color: #666; font-size: 0.95em; margin-bottom:0;">Distribui√ß√£o do n√∫mero de fam√≠lias afetadas por conflitos por munic√≠pio.</p>
        </div>""", unsafe_allow_html=True)
        st.plotly_chart(fig_familias(df_confmun_raw), use_container_width=True, height=400, key="familias")
        st.caption("Figura 3.1: Distribui√ß√£o de fam√≠lias afetadas por munic√≠pio.")
        with st.expander("Detalhes e Fonte da Figura 3.1"):
            st.write("""
            **Interpreta√ß√£o:**
            O gr√°fico apresenta o n√∫mero total de fam√≠lias afetadas por conflitos em cada munic√≠pio.

            **Observa√ß√µes:**
            - Dados agregados por munic√≠pio
            - Valores apresentados em ordem decrescente
            - Inclui todos os tipos de conflitos registrados

            **Fonte:** CPT - Comiss√£o Pastoral da Terra. *Conflitos no Campo Brasil*. Goi√¢nia: CPT Nacional, 2025. Dispon√≠vel em: https://www.cptnacional.org.br/. Acesso em: maio de 2025.
            """)
    with col_conf:
        st.markdown("""<div style="background-color: #fff; border-radius: 6px; padding: 1.5rem; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 0.5rem;">
            <h3 style="color: #1E1E1E; margin-top: 0; margin-bottom: 0.5rem;">Conflitos Registrados</h3>
            <p style="color: #666; font-size: 0.95em; margin-bottom:0;">N√∫mero total de conflitos registrados por munic√≠pio.</p>
        </div>""", unsafe_allow_html=True)
        st.plotly_chart(fig_conflitos(df_confmun_raw), use_container_width=True, height=400, key="conflitos")
        st.caption("Figura 3.2: Distribui√ß√£o de conflitos registrados por munic√≠pio.")
        with st.expander("Detalhes e Fonte da Figura 3.2"):
            st.write("""
            **Interpreta√ß√£o:**
            O gr√°fico mostra o n√∫mero total de conflitos registrados em cada munic√≠pio.

            **Observa√ß√µes:**
            - Contagem total de ocorr√™ncias por munic√≠pio
            - Ordena√ß√£o por quantidade de conflitos
            - Inclui todos os tipos de conflitos documentados

            **Fonte:** CPT - Comiss√£o Pastoral da Terra. *Conflitos no Campo Brasil*. Goi√¢nia: CPT Nacional, 2025. Dispon√≠vel em: https://www.cptnacional.org.br/. Acesso em: maio de 2025.
            """)

    st.markdown("---")
    st.markdown("""<div style="background-color: #fff; border-radius: 6px; padding: 1.5rem; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin: 1rem 0 0.5rem 0;">
        <h3 style="color: #1E1E1E; margin-top: 0; margin-bottom: 0.5rem;">Tabela Consolidada de Impactos Sociais</h3>
        <p style="color: #666; font-size: 0.95em; margin-bottom:0;">Dados consolidados de impactos sociais por munic√≠pio.</p>
    </div>""", unsafe_allow_html=True)
    st.dataframe(styled_df, use_container_width=True, hide_index=True)
    st.caption("Tabela 3.1: Dados consolidados de impactos sociais por munic√≠pio.")
    with st.expander("Detalhes e Fonte da Tabela 3.1"):
        st.write("""
        **Interpreta√ß√£o:**
        A tabela apresenta os dados consolidados por munic√≠pio, incluindo:
        - N√∫mero de fam√≠lias afetadas por conflitos
        - Quantidade de conflitos registrados
        - Quantidade de ocupa√ß√µes retomadas

        **Observa√ß√µes:**
        - Valores absolutos por munic√≠pio
        - Totais na √∫ltima linha
        - C√©lulas coloridas por tipo de dado
        - Ordena√ß√£o por n√∫mero de fam√≠lias afetadas

        **Fonte:** CPT - Comiss√£o Pastoral da Terra. *Conflitos no Campo Brasil*. Goi√¢nia: CPT Nacional, 2025. Dispon√≠vel em: https://www.cptnacional.org.br/. Acesso em: maio de 2025.
        """)
    st.divider()

with tabs[2]:
    st.header("Processos Judiciais")
    
    with st.expander("‚ÑπÔ∏è Sobre esta se√ß√£o", expanded=True):
        st.write("""
        Esta an√°lise apresenta dados sobre processos judiciais relacionados a quest√µes ambientais, incluindo:
        - Distribui√ß√£o por munic√≠pios
        - Classes processuais
        - Assuntos
        - √ìrg√£os julgadores
        
        Os dados s√£o provenientes do Tribunal de Justi√ßa do Estado do Par√°.
        """)
    
    st.markdown(
        "**Fonte Geral da Se√ß√£o:** CNJ - Conselho Nacional de Justi√ßa.",
        unsafe_allow_html=True
    )
    
    # Load df_proc_raw here as it's specific to this tab
    df_proc_raw = load_df_proc(
        r"processos_tjpa_completo_atualizada_pronto.csv",
        columns=df_proc_cols
    )

    if 'data_ajuizamento' in df_proc_raw.columns:
        df_proc_raw['data_ajuizamento'] = pd.to_datetime(df_proc_raw['data_ajuizamento'], errors='coerce')
    if 'ultima_atualiza√ßao' in df_proc_raw.columns:
        df_proc_raw['ultima_atualiza√ßao'] = pd.to_datetime(df_proc_raw['ultima_atualiza√ßao'], errors='coerce')

    figs_j = fig_justica(df_proc_raw)
    
    cols = st.columns(2, gap="large")
    
    with cols[0]:
        st.markdown("""
        <div style="background:#fff;border-radius:6px;padding:1.5rem;box-shadow:0 2px 4px rgba(0,0,0,0.1);margin-bottom:0.5rem;">
        <h3 style="margin:0 0 .5rem 0;">Top 10 Munic√≠pios</h3>
        <p style="margin:0;font-size:.95em;color:#666;">Munic√≠pios com maior n√∫mero de processos.</p>
        </div>
        """, unsafe_allow_html=True)
        
        if 'mun' in figs_j and figs_j['mun'] is not None:
            st.plotly_chart(figs_j['mun'].update_layout(height=400), use_container_width=True, key="jud_mun")
        else:
            st.warning("Gr√°fico de munic√≠pios n√£o p√¥de ser gerado.")
        
        st.caption("Figura 4.1: Top 10 munic√≠pios com mais processos.")
        with st.expander("‚ÑπÔ∏è Detalhes e Fonte da Figura 4.1", expanded=False):
            st.write("""
            **Interpreta√ß√£o:**
            Distribui√ß√£o dos processos por munic√≠pios.
            
            **Fonte:** CNJ - Conselho Nacional de Justi√ßa.
            """)
    
    with cols[1]:
        st.markdown("""
        <div style="background:#fff;border-radius:6px;padding:1.5rem;box-shadow:0 2px 4px rgba(0,0,0,0.1);margin-bottom:0.5rem;">
        <h3 style="margin:0 0 .5rem 0;">Classes Processuais</h3>
        <p style="margin:0;font-size:.95em;color:#666;">Top 10 classes mais frequentes.</p>
        </div>
        """, unsafe_allow_html=True)
        
        if 'class' in figs_j and figs_j['class'] is not None:
            st.plotly_chart(figs_j['class'].update_layout(height=400), use_container_width=True, key="jud_class")
        else:
            st.warning("Gr√°fico de classes n√£o p√¥de ser gerado.")
        
        st.caption("Figura 4.2: Top 10 classes processuais.")
        with st.expander("‚ÑπÔ∏è Detalhes e Fonte da Figura 4.2", expanded=False):
            st.write("""
            **Interpreta√ß√£o:**
            Distribui√ß√£o dos processos por classes processuais.
            
            **Fonte:** CNJ - Conselho Nacional de Justi√ßa.
            """)
    
    cols2 = st.columns(2, gap="large")
    
    with cols2[0]:
        st.markdown("""
        <div style="background:#fff;border-radius:6px;padding:1.5rem;box-shadow:0 2px 4px rgba(0,0,0,0.1);margin-bottom:0.5rem;">
        <h3 style="margin:0 0 .5rem 0;">Assuntos</h3>
        <p style="margin:0;font-size:.95em;color:#666;">Top 10 assuntos mais recorrentes.</p>
        </div>
        """, unsafe_allow_html=True)
        
        if 'ass' in figs_j and figs_j['ass'] is not None:
            st.plotly_chart(figs_j['ass'].update_layout(height=400), use_container_width=True, key="jud_ass")
        else:
            st.warning("Gr√°fico de assuntos n√£o p√¥de ser gerado.")
        
        st.caption("Figura 4.3: Top 10 assuntos.")
        with st.expander("‚ÑπÔ∏è Detalhes e Fonte da Figura 4.3", expanded=False):
            st.write("""
            **Interpreta√ß√£o:**
            Distribui√ß√£o dos processos por assuntos.
            
            **Fonte:** CNJ - Conselho Nacional de Justi√ßa.
            """)
    
    with cols2[1]:
        st.markdown("""
        <div style="background:#fff;border-radius:6px;padding:1.5rem;box-shadow:0 2px 4px rgba(0,0,0,0.1);margin-bottom:0.5rem;">
        <h3 style="margin:0 0 .5rem 0;">√ìrg√£os Julgadores</h3>
        <p style="margin:0;font-size:.95em;color:#666;">Top 10 √≥rg√£os com mais processos.</p>
        </div>
        """, unsafe_allow_html=True)
        
        if 'org' in figs_j and figs_j['org'] is not None:
            st.plotly_chart(figs_j['org'].update_layout(height=400), use_container_width=True, key="jud_org")
        else:
            st.warning("Gr√°fico de √≥rg√£os julgadores n√£o p√¥de ser gerado.")
        
        st.caption("Figura 4.4: Top 10 √≥rg√£os julgadores.")
        with st.expander("‚ÑπÔ∏è Detalhes e Fonte da Figura 4.4", expanded=False):
            st.write("""
            **Interpreta√ß√£o:**
            Distribui√ß√£o dos processos por √≥rg√£os julgadores.
            
            **Fonte:** CNJ - Conselho Nacional de Justi√ßa.
            """)
    
    st.markdown("""
    <div style="background:#fff;border-radius:6px;padding:1.5rem;box-shadow:0 2px 4px rgba(0,0,0,0.1);margin:1rem 0 .5rem 0;">
    <h3 style="margin:0 0 .5rem 0;">Evolu√ß√£o Mensal de Processos</h3>
    <p style="margin:0;font-size:.95em;color:#666;">Varia√ß√£o mensal ao longo do per√≠odo.</p>
    </div>
    """, unsafe_allow_html=True)
    
    if 'temp' in figs_j and figs_j['temp'] is not None:
        st.plotly_chart(figs_j['temp'], use_container_width=True, key="jud_temp")
    else:
        st.warning("Gr√°fico de evolu√ß√£o temporal n√£o p√¥de ser gerado.")
    
    st.caption("Figura 4.5: Evolu√ß√£o temporal dos processos judiciais.")
    with st.expander("‚ÑπÔ∏è Detalhes e Fonte da Figura 4.5", expanded=False):
        st.write("""
        **Interpreta√ß√£o:**
        Evolu√ß√£o mensal dos processos.
        
        **Fonte:** CNJ - Conselho Nacional de Justi√ßa.
        """)
    st.markdown("""
    <div style="background:#fff;border-radius:6px;padding:1.5rem;box-shadow:0 2px 4px rgba(0,0,0,0.1);margin:1rem 0 .5rem 0;">
    <h3 style="margin:0 0 .5rem 0;">An√°lise Interativa de Processos</h3>
    <p style="margin:0;font-size:.95em;color:#666;">Tabela com filtros para an√°lise detalhada dos dados.</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        tipo_analise = st.selectbox(
            "Escolha o tipo de an√°lise:",
            ["Munic√≠pios com mais processos", "√ìrg√£os mais atuantes", "Classes processuais mais frequentes", "Assuntos mais recorrentes", "Dados gerais relevantes"],
            key="tipo_analise_proc"
        )
    
    with col2:
        if 'data_ajuizamento' in df_proc_raw.columns:
            df_proc_raw['ano'] = pd.to_datetime(df_proc_raw['data_ajuizamento'], errors='coerce').dt.year
            anos_disponiveis = sorted([ano for ano in df_proc_raw['ano'].dropna().unique() if not pd.isna(ano)])
            if anos_disponiveis:
                ano_selecionado = st.selectbox(
                    "Filtrar por ano:",
                    ["Todos os anos"] + anos_disponiveis,
                    key="ano_filter_proc"
                )
            else:
                ano_selecionado = "Todos os anos"
        else:
            ano_selecionado = "Todos os anos"
    
    df_proc_filtered_year = df_proc_raw.copy()
    if ano_selecionado != "Todos os anos":
        df_proc_filtered_year = df_proc_filtered_year[df_proc_filtered_year['ano'] == ano_selecionado]
    
    df_filtrado = df_proc_filtered_year.copy()

    if tipo_analise == "Munic√≠pios com mais processos":
        if 'municipio' in df_filtrado.columns and 'numero_processo' in df_filtrado.columns and 'data_ajuizamento' in df_filtrado.columns:
            df_filtrado['municipio'] = df_filtrado['municipio'].apply(clean_text)
            tabela_resumo = df_filtrado.groupby('municipio', observed=False).agg({
                'numero_processo': 'count',
                'data_ajuizamento': ['min', 'max']
            }).round(2)
            tabela_resumo.columns = ['Total de Processos', 'Primeiro Processo', '√öltimo Processo']
            tabela_resumo = tabela_resumo.sort_values('Total de Processos', ascending=False).head(20)
            tabela_resumo = tabela_resumo.reset_index()
            
            st.dataframe(tabela_resumo, use_container_width=True)
            st.caption("Tabela 4.1: Top 20 munic√≠pios com mais processos judiciais.")
        else:
             st.info("Dados insuficientes para gerar esta tabela.")
        
    elif tipo_analise == "√ìrg√£os mais atuantes":
        if 'orgao_julgador' in df_filtrado.columns and 'numero_processo' in df_filtrado.columns and 'data_ajuizamento' in df_filtrado.columns:
            df_filtrado['orgao_julgador'] = df_filtrado['orgao_julgador'].apply(clean_text)
            tabela_resumo = df_filtrado.groupby('orgao_julgador', observed=False).agg({
                'numero_processo': 'count',
                'data_ajuizamento': ['min', 'max']
            }).round(2)
            tabela_resumo.columns = ['Total de Processos', 'Primeiro Processo', '√öltimo Processo']
            tabela_resumo = tabela_resumo.sort_values('Total de Processos', ascending=False).head(15)
            tabela_resumo = tabela_resumo.reset_index()
            
            st.dataframe(tabela_resumo, use_container_width=True)
            st.caption("Tabela 4.1: Top 15 √≥rg√£os julgadores mais atuantes.")
        else:
             st.info("Dados insuficientes para gerar esta tabela.")

    elif tipo_analise == "Classes processuais mais frequentes":
        if 'classe' in df_filtrado.columns and 'numero_processo' in df_filtrado.columns and 'data_ajuizamento' in df_filtrado.columns:
            df_filtrado['classe'] = df_filtrado['classe'].apply(clean_text)
            tabela_resumo = df_filtrado.groupby('classe', observed=False).agg({
                'numero_processo': 'count',
                'data_ajuizamento': ['min', 'max']
            }).round(2)
            tabela_resumo.columns = ['Total de Processos', 'Primeiro Processo', '√öltimo Processo']
            tabela_resumo = tabela_resumo.sort_values('Total de Processos', ascending=False).head(15)
            tabela_resumo = tabela_resumo.reset_index()
            
            st.dataframe(tabela_resumo, use_container_width=True)
            st.caption("Tabela 4.1: Top 15 classes processuais mais frequentes.")
        else:
             st.info("Dados insuficientes para gerar esta tabela.")

    elif tipo_analise == "Assuntos mais recorrentes":
        if 'assuntos' in df_filtrado.columns and 'numero_processo' in df_filtrado.columns and 'data_ajuizamento' in df_filtrado.columns:
            df_filtrado['assuntos'] = df_filtrado['assuntos'].apply(clean_text)
            tabela_resumo = df_filtrado.groupby('assuntos', observed=False).agg({
                'numero_processo': 'count',
                'data_ajuizamento': ['min', 'max']
            }).round(2)
            tabela_resumo.columns = ['Total de Processos', 'Primeiro Processo', '√öltimo Processo']
            tabela_resumo = tabela_resumo.sort_values('Total de Processos', ascending=False).head(15)
            tabela_resumo = tabela_resumo.reset_index()
            
            st.dataframe(tabela_resumo, use_container_width=True)
            st.caption("Tabela 4.1: Top 15 assuntos mais recorrentes.")
        else:
             st.info("Dados insuficientes para gerar esta tabela.")

    else: 
        colunas_relevantes = ['numero_processo', 'data_ajuizamento', 'municipio', 'classe', 'assuntos', 'orgao_julgador']
        colunas_existentes = [col for col in colunas_relevantes if col in df_filtrado.columns]
        
        if colunas_existentes:
            df_relevante = df_filtrado[colunas_existentes].copy()
            
            for col in ['municipio', 'classe', 'assuntos', 'orgao_julgador']:
                if col in df_relevante.columns:
                    df_relevante[col] = df_relevante[col].apply(clean_text)
            
            if 'data_ajuizamento' in df_relevante.columns:
                df_relevante = df_relevante.sort_values('data_ajuizamento', ascending=False)
            
            st.dataframe(df_relevante.head(500), use_container_width=True)
            st.caption("Tabela 4.1: Dados gerais relevantes dos processos judiciais (limitado a 500 registros).")
        else:
            st.info("N√£o foi poss√≠vel carregar os dados relevantes.")
    
    with st.expander("‚ÑπÔ∏è Sobre esta tabela", expanded=False):
        if tipo_analise == "Munic√≠pios com mais processos":
            st.write("""
            Esta tabela mostra os munic√≠pios com maior n√∫mero de processos judiciais,
            incluindo o total de processos e o per√≠odo de atua√ß√£o (primeiro e √∫ltimo processo).
            """)
        elif tipo_analise == "√ìrg√£os mais atuantes":
            st.write("""
            Esta tabela apresenta os √≥rg√£os julgadores com maior volume de processos,
            mostrando sua atividade ao longo do tempo.
            """)
        elif tipo_analise == "Classes processuais mais frequentes":
            st.write("""
            Esta tabela mostra as classes processuais mais utilizadas nos processos judiciais,
            indicando os tipos de a√ß√µes mais comuns no sistema judici√°rio.
            """)
        elif tipo_analise == "Assuntos mais recorrentes":
            st.write("""
            Esta tabela apresenta os assuntos mais frequentes nos processos judiciais,
            revelando as principais quest√µes levadas ao judici√°rio.
            """)
        else:
            st.write("""
            Esta tabela apresenta os dados gerais mais relevantes dos processos judiciais,
            ordenados por data de ajuizamento (mais recentes primeiro).
            Limitada a 500 registros para melhor performance.
            """)
    
    st.markdown(
        "**Fonte:** CNJ - Conselho Nacional de Justi√ßa.",
        unsafe_allow_html=True
    )

with tabs[3]:
    # This content is now inside renderizar_aba_queimadas()
    pass # Placeholder for the diff tool, original content moved into the function

with tabs[4]:
    st.header("Desmatamento")

    with st.expander("‚ÑπÔ∏è Sobre esta se√ß√£o", expanded=True):
        st.write("""
        Esta an√°lise apresenta dados sobre √°reas de alerta de desmatamento, incluindo:
        - Distribui√ß√£o por Unidade de Conserva√ß√£o
        - Evolu√ß√£o temporal
        - Distribui√ß√£o por munic√≠pio
        - Distribui√ß√£o espacial (Mapa)

        Os dados s√£o provenientes do MapBiomas Alerta.
        """)
        st.markdown(
            "**Fonte Geral da Se√ß√£o:** MapBiomas Alerta. Plataforma de Dados de Alertas de Desmatamento. Dispon√≠vel em: https://alerta.mapbiomas.org/. Acesso em: maio de 2025.",
            unsafe_allow_html=True
        )

    st.write("**Filtro Global:**")
    anos_disponiveis = ['Todos'] + sorted(gdf_alertas_raw['ANODETEC'].dropna().unique().tolist())
    ano_global_selecionado = st.selectbox('Ano de Detec√ß√£o:', anos_disponiveis, key="filtro_ano_global")

    if ano_global_selecionado != 'Todos':
        gdf_alertas_filtrado = gdf_alertas_raw[gdf_alertas_raw['ANODETEC'] == ano_global_selecionado].copy()
    else:
        gdf_alertas_filtrado = gdf_alertas_raw.copy()

    st.divider()

    col_charts, col_map = st.columns([2, 3], gap="large")

    with col_charts:
        if not gdf_cnuc_raw.empty and not gdf_alertas_filtrado.empty:
            fig_desmat_uc = fig_desmatamento_uc(gdf_cnuc_raw, gdf_alertas_filtrado)
            if fig_desmat_uc and fig_desmat_uc.data:
                st.subheader("√Årea de Alertas por UC")
                st.plotly_chart(fig_desmat_uc, use_container_width=True, height=400, key="desmat_uc_chart")
                st.caption("Figura 6.1: √Årea total de alertas de desmatamento por unidade de conserva√ß√£o.")
                with st.expander("Detalhes e Fonte da Figura 6.1"):
                    st.write("""
                    **Interpreta√ß√£o:**
                    O gr√°fico mostra a √°rea total (em hectares) de alertas de desmatamento detectados dentro de cada unidade de conserva√ß√£o.

                    **Observa√ß√µes:**
                    - Barras representam a √°rea total de alertas em hectares por UC.
                    - A linha tracejada indica a m√©dia da √°rea de alertas entre as UCs exibidas.
                    - Ordenado por √°rea de alertas em ordem decrescente.

                    **Fonte:** MapBiomas Alerta. *Plataforma de Dados de Alertas de Desmatamento*. Dispon√≠vel em: https://alerta.mapbiomas.org/. Acesso em: maio de 2025.
                    """)
            else:
                st.info("Nenhum alerta de desmatamento encontrado sobrepondo as Unidades de Conserva√ß√£o para o per√≠odo selecionado.")
        else:
            st.warning("Dados de Unidades de Conserva√ß√£o ou Alertas de Desmatamento n√£o dispon√≠veis para esta an√°lise.")

        st.divider()

    with col_map:
        if not gdf_alertas_filtrado.empty:
            minx, miny, maxx, maxy = gdf_alertas_filtrado.total_bounds
            centro_filtered = {'lat': (miny + maxy) / 2, 'lon': (minx + maxx) / 2}
            fig_desmat_map_pts = fig_desmatamento_mapa_pontos(gdf_alertas_filtrado)
            if fig_desmat_map_pts and fig_desmat_map_pts.data:
                st.subheader("Mapa de Alertas")
                st.plotly_chart(
                    fig_desmat_map_pts,
                    use_container_width=True,
                    height=850,
                    config={'scrollZoom': True},
                    key="desmat_mapa_pontos_chart"
                )
                st.caption("Figura 6.3: Distribui√ß√£o espacial dos alertas de desmatamento.")
                with st.expander("Detalhes e Fonte da Figura"):
                    st.write("""
                    **Interpreta√ß√£o:**
                    O mapa mostra a localiza√ß√£o e a √°rea (representada pelo tamanho e cor do ponto) dos alertas de desmatamento.

                    **Observa√ß√µes:**
                    - Cada ponto representa um alerta de desmatamento.
                    - O tamanho e a cor do ponto s√£o proporcionais √† √°rea desmatada (em hectares).
                    - √Åreas com maior concentra√ß√£o de pontos indicam maior atividade de desmatamento.

                    **Fonte:** MapBiomas Alerta. *Plataforma de Dados de Alertas de Desmatamento*. Dispon√≠vel em: https://alerta.mapbiomas.org/. Acesso em: maio de 2025.
                    """)
            else:
                st.info("Dados de alertas de desmatamento n√£o cont√™m informa√ß√µes geogr√°ficas v√°lidas para o mapa no per√≠odo selecionado.")
        else:
            st.warning("Dados de Alertas de Desmatamento n√£o dispon√≠veis para esta an√°lise.")

    st.divider()
    st.subheader("Ranking de Munic√≠pios por Desmatamento")
    if not gdf_alertas_filtrado.empty:
        required_ranking_cols = ['ESTADO', 'MUNICIPIO', 'AREAHA', 'ANODETEC', 'BIOMA', 'VPRESSAO']
        if all(col in gdf_alertas_filtrado.columns for col in required_ranking_cols):
            gdf_alertas_filtrado['AREAHA'] = pd.to_numeric(gdf_alertas_filtrado['AREAHA'], errors='coerce')

            ranking_municipios = gdf_alertas_filtrado.groupby(['ESTADO', 'MUNICIPIO'], observed=False).agg({
                'AREAHA': ['sum', 'count', 'mean'],
                'ANODETEC': ['min', 'max'],
                'BIOMA': lambda x: x.mode().iloc[0] if not x.empty and x.mode().size > 0 else 'N/A',
                'VPRESSAO': lambda x: x.mode().iloc[0] if not x.empty and x.mode().size > 0 else 'N/A'
            }).round(2)
            ranking_municipios.columns = ['√Årea Total (ha)', 'Qtd Alertas', '√Årea M√©dia (ha)',
                                          'Ano Min', 'Ano Max', 'Bioma Principal', 'Vetor Press√£o']

            ranking_municipios = ranking_municipios.reset_index()
            ranking_municipios = ranking_municipios.sort_values('√Årea Total (ha)', ascending=False)
            ranking_municipios.insert(0, 'Posi√ß√£o', range(1, len(ranking_municipios) + 1))

            ranking_municipios['√Årea Total (ha)'] = ranking_municipios['√Årea Total (ha)'].apply(lambda x: f"{x:,.2f}")
            ranking_municipios['√Årea M√©dia (ha)'] = ranking_municipios['√Årea M√©dia (ha)'].apply(lambda x: f"{x:.2f}")

            st.dataframe(
                ranking_municipios.head(10),
                use_container_width=True,
                hide_index=True,
                height=400
            )
            st.caption("Tabela 6.1: Ranking dos munic√≠pios com maior √°rea de alertas de desmatamento (Top 10).")
            with st.expander("Detalhes da Tabela 6.1 e Informa√ß√µes das Colunas"):
                st.write("""
                **Interpreta√ß√£o:**
                Ranking dos munic√≠pios ordenados pela √°rea total de alertas de desmatamento detectados, com informa√ß√µes complementares sobre quantidade de alertas, per√≠odo e caracter√≠sticas predominantes.

                **Informa√ß√µes das Colunas:**
                - **Posi√ß√£o**: Ranking baseado na √°rea total de desmatamento
                - **Estado**: Estado onde se localiza o munic√≠pio
                - **Munic√≠pio**: Munic√≠pio onde se localiza o alerta
                - **√Årea Total (ha)**: Soma de todas as √°reas de alertas do munic√≠pio em hectares
                - **Qtd Alertas**: Quantidade total de alertas detectados no munic√≠pio
                - **√Årea M√©dia (ha)**: √Årea m√©dia por alerta no munic√≠pio
                - **Ano Min/Max**: Per√≠odo de detec√ß√£o dos alertas (primeiro e √∫ltimo ano)
                - **Bioma Principal**: Bioma mais frequente nos alertas do munic√≠pio
                - **Vetor Press√£o**: Principal vetor de press√£o detectado nos alertas

                **Fonte:** MapBiomas Alerta. *Plataforma de Dados de Alertas de Desmatamento*. Dispon√≠vel em: https://alerta.mapbiomas.org/. Acesso em: maio de 2025.
                """)
        else:
            st.info("Dados insuficientes para gerar o ranking de munic√≠pios.")
    else:
        st.info("Dados n√£o dispon√≠veis para o ranking no per√≠odo selecionado")

    st.divider()

    if not gdf_alertas_raw.empty:
        fig_desmat_temp = fig_desmatamento_temporal(gdf_alertas_raw)
        if fig_desmat_temp and fig_desmat_temp.data:
            st.subheader("Evolu√ß√£o Temporal de Alertas")
            st.plotly_chart(fig_desmat_temp, use_container_width=True, height=400, key="desmat_temporal_chart")
            st.caption("Figura 6.4: Evolu√ß√£o mensal da √°rea total de alertas de desmatamento.")
            with st.expander("Detalhes e Fonte da Figura 6.4"):
                st.write("""
                **Interpreta√ß√£o:**
                O gr√°fico de linha mostra a varia√ß√£o mensal da √°rea total (em hectares) de alertas de desmatamento ao longo do tempo.

                **Observa√ß√µes:**
                - Cada ponto representa a soma da √°rea de alertas para um determinado m√™s.
                - A linha conecta os pontos para mostrar a tend√™ncia temporal.
                - Valores s√£o exibidos acima de cada ponto para facilitar a leitura.

                **Fonte:** MapBiomas Alerta. *Plataforma de Dados de Alertas de Desmatamento*. Dispon√≠vel em: https://alerta.mapbiomas.org/. Acesso em: maio de 2025.
                """)
        else:
            st.info("Dados de alertas de desmatamento n√£o cont√™m informa√ß√µes temporais v√°lidas.")
    else:
        st.warning("Dados de Alertas de Desmatamento n√£o dispon√≠veis para esta an√°lise.")
